[
  {
    "id": "X690ZObNf_w",
    "title": "Velvet Sundown, or, How Scared Should We Be of AI Music?",
    "published_at": "2025-07-04T01:12:21Z",
    "description": "A new band called Velvet Sundown appeared on Spotify with two albums and hundreds of thousands of listeners, but has no evidence of real members or a history online. Music sites note that the music sounds like it could be generated by AI tools, while the band insists it is real.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 723,
    "views": 1996,
    "likes": 73,
    "url": "https://youtube.com/watch?v=X690ZObNf_w",
    "transcript": "Welcome back to the AI Daily Brief. Last month, a new psychedelic rock band called The Velvet Sundown started appearing on people's playlists on Spotify. They dropped two albums and quickly racked up a couple of hundred thousand listeners on Spotify. The only problem is they probably don't actually exist. A Reddit user on the anti- AI subreddit posted, \"Behold, a completely fake band on Spotify with 300,000 monthly listeners. Not a shred of evidence on the internet that this band has ever existed. AI generated artist photo and album covers. Description reads like ChachiBT. A woman on Tik Tok said it was the first song in her Discover Weekly. I'm 100% sure this content is pushed by Spotify itself to further minimize the amount of money they pay artists. The potentially generated description, in case you're curious, reads, \"There's something quietly spellbinding about The Velvet Sundown. You don't just listen to them, you drift into them. Their music doesn't shout for your attention. It seeps in slowly, like a scent that suddenly takes you back somewhere you didn't expect. Their sound mixes textures of 70s psychedelic alt rock and folk rock, yet it blends effortlessly with modern alt pop and indie structures. Shimmering tremolos, warm tape reverbs, and the gentle swirl of organs give everything a sense of history without it ever feeling forced. The Velvet Sundown aren't trying to revive the past. They're rewriting it. They sound like the memory of a time that never actually happened, but somehow they make it feel real. Now, while there might not be any M dashes in this, it certainly does sound like the kind of schllock that you might get from chat GPT. So, is this band an AI construct? And if they are, does it matter? In the past week or so, the Velvet Sundown has become a very hot topic of conversation in music and internet cultural media. Consequently, we have multiple deep dive investigations trying to figure out whether in fact the band is AI generated. The first and perhaps most obvious indication is the pictures. I think for anyone who has spent any time with AI, they certainly have that feel of AI generation. The album covers are almost certainly AI generated, even if the rest of the band is not. But at this point, it should be pointed out that having AI generated covers and AI generated descriptions doesn't make the band fake. It just makes them like pretty much everyone else at this point who is using AI for generating images and generating descriptions. A bigger tell is that none of the band members seem to actually exist. They don't have any social media accounts, haven't done interviews, and in fact have zero internet presence whatsoever. In fact, the band social media presence only spawned recently once they started getting media attention. Their Instagram is filled with very obvious AI generated photos, and the song's credits are also suspicious with no producers or extra writers outside of the band listed. Then there are the songs themselves. Music Radar wrote, \"The band's country tinged roots rock bears the unmistakable lowfi veneer of auno creation, but is convincing enough to pass by undetected if sandwiched in a playlist between two authentic songs. And indeed, while most of their listens now are curiosity after people have read articles like this one, the initial couple hundred thousand listeners came largely from Spotify's generated playlists like Discover Weekly. A huge amount of Spotify listenership is in the form of personalized playlists that are generated by Spotify's recommendation algorithm. In a post on X the band denied the rumors with a bio that reads, \"Yes, we are a real band and we never use AI # neverai,\" they wrote a thread, \"Absolutely crazy that so-called journalists keep pushing the lazy baseless theory that the Velvet Sundown is AI generated with zero evidence. Not a single one of these quote unquote writers has reached out, visited a show, or listened beyond the Spotify algorithm. This is not a joke. This is our music written in long, sweaty nights in a cramped bungalow in California with real instruments, real minds, and real soul. Every chord, every lyric, every mistake, human. Just because we don't do Tik Tok dances or live stream our process doesn't mean we're fake. The fact that some blog editors would rather pretend we're a bunch of machines than admit an unknown band is out here grinding and made something people enjoy is insulting. We've had to lock down our personal accounts due to harassment, all because some writer wanted clicks and couldn't imagine people like us existing outside their sanitized indie media echo chamber. Shame on every outlet amplifying this narrative. We are real. Think next time before you erase people. Forgive me for piling on, but me thinks that Lady Doth protests too much. Indeed, when it comes to whether the Velvet Sundown is a real band or an AI generated art piece, if I were a betting man, I would put basically all of my chips on it being some sort of very intentional experiment that's meant to provoke exactly the conversation it's provoking. Now, what I don't know is to what extent it's from a pro-AI or anti-AI source, but it's definitely trying to provoke a conversation. And so, let's have that conversation. One of the things that's really interesting about this is that in other social media channels, think Tik Tok and YouTube, there is an incredible amount of AI content that is self-professed and unabashed. There's the Bigfoot and Yeti videos, Vlog Warts, all of these things that I profiled recently in another episode. music hasn't yet seen that level of infiltration. Yes, we have had a couple of breakout moments in AI music. King Wonius's BBL Drizzy being used during the whole Drake Kendrick feud was a really notable one. And again on Spotify, there are accounts like Beats by AI official, which use AI to create humorous songs that have racked up just an incredible number of views and 10 million likes, but which again are very, very clear. Beats by AI official got its start with a series of posts called asking AI to make a hit country song. It did it every day for months, eventually built an audience and turned that into some very humorous and very not safe for work songs. And yet, broadly speaking, there is definitely a stronger reaction against AI music than AI and other creative genres. A piece in music business worldwide recently was called the AI music problem on Spotify is worse than you think. They point to outlaw country artist Aanthis which has over a million listeners each month and which is for sure and known to be AI generated. Now in the case of Aanthis it does appear to be a little bit more of an intentional product from a musician. When someone a couple of months ago asked in a YouTube comment what role AI played in the artist music, the anonymous owner of the channel replied, \"The voice and image is created with the help of AI. The lyrics are written by me.\" And if you go to the credits on Spotify, the written by and produced by is someone named David Vieiraa. The article then goes on to point out a couple of other examples coming of course to the Velvet Sundown. And if you go check out Twitter/X, there are people like Anju Online who write, \"Not enough music people are actually paying attention to this Velvet Sundown situation. The future of streaming services is about to be so bleak.\" Cohenrad Sheepers writes, \"AI now births entire music acts. I came across the Velvet Sundown, which has lyrics, vocals, and visuals, all generated by AI. This again just highlights how its creative output is outpacing our ability to regulate it. Scary part is that I would 100% listen to this over many quote unquote real artists. Masimo at Rainmaker 1973 writes, \"The Velvet Sundown apparently has only existed for 2 weeks and has over 400,000 monthly listeners. It's a totally generated AI band. easily. People who primarily interface with music via algorithmically generated playlists will soon only listen to AI generated music. Signal writes, \"These guys are only two weeks old. 411,000 Spotify listeners and entirely AI generated. This is the first time I've seen a totally synthetic act hit cultural velocity this fast. Whoever made this didn't just use AI, they understood narrative. And this is just the beginning. There is a lot to unpack here. First of all, while I agree entirely that whoever is behind The Velvet Sundown is creating an entire experience that understands narrative and is not just about the music, I don't think it's fair to claim that there's actual cultural velocity here. These are not hit songs. These are not diehard fans. These are Curiosity listeners, at least half of which have come pretty directly from the articles about the Curiosity that is this band. One way to tell is the disparity between the monthly listeners and the followers. There have been 634,000 monthly listeners, but only 11,000 people have actually decided to follow the band. Now, what's super clear is that there is going to be more of this type of experimentation. Sometimes people will anonymously use AI. Sometimes musicians will explicitly and clearly use AI. But like any other technology tool, it is going to impact the music that gets created. There are inevitably going to be AI generated hits. It is just absolutely inevitable. What's more, there is an incredibly large market for background music in everything from videos to games that will likely find its way to AI generation as a cheaper solve. The question is how problematic is this? And from a creativity standpoint, I don't think that the introduction of AI somehow threatens human creativity without AI. That's basically what my entire interview with Rick Rubin was about. Where it gets more dicey and where I think people are reacting is to what extent AI generated music competes with human generated music for limited attention. And the irony here is that the AI that I think people are actually angry at is not in fact AI generated music. It is instead the tyranny of the algorithm. None of this is new, so forgive me for trying to make it sound profound. The reality is is that we live in an algorithmically mediated world. The social networks where we consume content, media, news, music, videos, all of it is carefully curated for us based on micro expressions of our interest and intent. All which get sucked into a big AI Borg and spit back out at us things that it thinks we will like. The Velvet Sundown sounds like a very particular type of band. It's not surprising that the Spotify algorithm is picking up that if you like other types of bands in this genre, you might respond positively to them as well. And I think in some ways what people are reacting to is the idea of being forced to consume something which feels artificial. What makes this whole moment so interesting to me is that we are talking about the confluence of two types of AI. New AI generated content and the algorithm run channels where that content gets discovered. As I discussed in that show about AI video, it's very clear that AI is taking over some of those algorithm channels already. But it wouldn't be all that surprising to me if people have a different type of reaction in music and want a different approach. Forever ago, literally more than 2 years ago, Product Hunt founder Ryan Hoover wrote free startup idea that will likely get you sued. AI Spotify. How it works. AI Spotify hosts AI generated music from your favorite artists. Anyone can submit music and the best songs surface based on listens and likes. Music with the most listens earns a prorat a share of subscription revenue reserved for the original artists. For example, Drake could claim money generated from his likeness on the platform. Artists that do not want to participate can opt out entirely, banning any music that uses their likeness or individually allow songs they endorse. Of course, there are many ethical and legal issues with this model, especially with labels. But maybe this is a germ of a shower thought that has potential. Now, at the time, what we were focused on was how people were making songs that imitated the voices of prominent artists. Obviously now with things like the Velvet Sundown, we're talking about artists that are generated from scratch. And so perhaps AI Spotify looks a little bit different, but it still wouldn't surprise me if we start to see some number of channels which reach escape velocity which are based on hosting new types of AI generation separate from other types of human creative experiences. Maybe not, and maybe it all gets integrated into one spot. But it feels like new types of content when they emerge tend to bring with them ultimately their own new networks as well. In fact, I think it would be surprising if we didn't see something similar with AI. For now, like I said, I'm pretty sure the Velvet Sundown is trying to provoke conversation. So, go check them out and then share what you think about it on your algorithmically mediated social network of choice. That's going to do it for today's AI Daily Brief. Until next time, peace."
  },
  {
    "id": "2TfHZEbQuZU",
    "title": "How AI Companies Are Using AI",
    "published_at": "2025-07-03T15:00:06Z",
    "description": "This episode explores a recent report on how AI companies themselves are utilizing AI. The discussion highlights key trends, including popular AI models, common deployment challenges like hallucinations, and the rapid rise of AI agents. It also examines prominent AI use cases delivering significant productivity gains—especially coding assistance—and discusses evolving business models and cost considerations as companies transition from experimentation to widespread implementation.\n\nReport: https://www.iconiqcapital.com/growth/reports/2025-state-of-ai\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 929,
    "views": 2592,
    "likes": 98,
    "url": "https://youtube.com/watch?v=2TfHZEbQuZU",
    "transcript": "Today on the AI daily brief, how AI companies are actually using AI. I've been really looking forward to talking about this report. Because whereas most of the reports that we have context to talk about on this show are from an enterprise vantage and enterprise adoption, which of course matches a lot of what you guys are doing, this is a report that's all about how the companies that are building AI are using AI. And I think that there's a sort of do what I do, not just what I say kind of thing that makes that really valuable. The report comes from Iconic who is a wealth manager and investment firm. And to cut to the chase, as much as it's distinct here and really useful, a lot of the big themes are very similar. In other words, we are firmly out of the pilot and experimentation stage. We are experimenting with new business models. Spend and budgets are increasing. Talent really matters. Really similar themes that you've heard me talk about in the past, but from companies that are frankly best positioned to know. So, what are the types of companies that are included in this? Despite these all being AI builders, there's actually quite a range. On the one end of the spectrum are AI enabled companies who are just adding AI capabilities to their existing products. So this is something like Atlassian who has work management software that's building an AI kind of version of that. That represents about 31% of these 300 survey respondents. Another category of AI enabled are the companies who are creating a new AI product that isn't their core product. So that's like Salesforce where agent force is obviously a huge priority for them but it's still not the core Salesforce product. That group represents 37% of the respondents. The last category are the AI native companies who are like 11 Labs where their whole focus is their core AI product and that's 32% of the respondents. Unsurprisingly the companies for whom their AI product is their main product are a little bit farther along in the development of their AI product. Whereas 34% of the AI enabled companies have their AI products still in beta. Only 10% of the AI native companies are stuck in beta. Both categories have around 42% general availability of their AI products. But whereas only 13% of AI enabled companies are scaling their AI products. A full 47% of the AI native companies are scaling their AI products. When it comes to what they're building, it is the big themes, man. its agentic workflows, vertical AI applications along with horizontal AI applications, AI platforms and infrastructure and core AI models. Still 62% of the AI enabled companies were working on agents in some form or fashion and 79% of the AI native companies were as well. One really interesting question certainly from the standpoint of those of you who are in big companies who are trying to make these types of decisions was what models they use and the clear answer is a number of them. In fact, the average number of models per respondent was 2.8. Meaning that to the extent that your company is laboring over a decision around which model to use, we may be at a stage where trying different models for different purposes may be the play. OpenAI was by far the leader with Anthropic in second place and Google and Meta being in pretty close quarters for third place. Mistral, Deepseek, and Coher also had some representation as well. Interestingly, when it came to considerations for which model to choose, accuracy was by far the top consideration. 74% of companies surveyed had accuracy in their top three considerations. On the other end of the spectrum, open source and vendor lockin were very, very low. Only 9% of companies had open source as a key consideration and only 6% had vendor lockin as a key consideration. Still one difference between 24 and 25 that was really interesting is that whereas in 24 cost was actually the lowest top consideration. This year it was number two with 57% of companies ranking it as a top three consideration. Now I think that that big jump reflects the fact that we have moved out of the experimentation phase and into the full production phase. In other words, when you are just experimenting and in beta tests, cost is a lower priority compared to just making the thing work. But when you're actually scaling a product that's going to have tons of usage, boy does cost make a big difference. On top of that, we also have external factors like lowerc cost models like DeepSeek coming in and competing, creating the opportunity for cost to be a consideration. When it came to the challenges they found with different models, I think the list will be pretty familiar to anyone interacting with AI. Hallucinations were at the top of the list, followed by explanability and trust, improving ROI, compute cost. An interesting one which we'll come back to in a little bit was a quarter of the respondents had listed finding the right use cases as a top three challenge which is interesting considering that these are companies who are building AI models and they're still a quarter of them finding the right use cases be a challenge what about the big theme agents the TLDDR is that agents are here baby iconic separated the groups into high growth and all other companies and among the high growth companies nearly half of them 47% were actively deploying AI agents in production with another 42% experimenting with AI agents in pilots or internal use cases. Even among all other companies, the non- high growths, a full around a third, 32% were actively deploying AI agents with another 32% in the pilot or experimentation phase. I thought that that 32% in deployment number was interesting because that's almost exactly the same number that KPMG's quarterly pulse survey found of big enterprises putting AI agents into deployment which was itself a huge jump from the previous quarter where it was just 11%. Now how are companies making all these decisions? The TLDDR is that once companies reach a certain scale or size, basically 100 million, they start to more frequently have dedicated AI leadership, and that percentage just goes up the bigger that they get. Across all sorts of different AI specific roles they are hiring at the top end are technical roles like AI engineers and data scientists. But you're also seeing prompt engineers still being hired, AI design specialists being hired, AI product managers are a major category. 46% say that they're not hiring fast enough. And of those, 60% say that hiring is too slow due to a lack of qualified candidates. Interestingly, the biggest cost center for companies is around talent. Now, that does go down over time as products scale, but it still represents a big chunk of the cost of these AI products. For example, among the companies that are actively scaling their AI products, a full 36% of their AI budget is allocated to salaries, hiring, and upskilling. that compares to, for example, 12% for AI model training and 10% for AI model inference. When it comes to which costs are hardest to control, there are a lot of things that people are considering. Storage costs, training costs, model retraining, inference costs, all have between 40 and 50% of respondents ranking them in the top three most challenging costs to control. But by far the leader in this category is API usage fees with a full 70% ranking it as a top challenge to control that cost. Now, in terms of how they're trying to control those costs, interestingly, although they didn't rank open source particularly important to them when it came to model consideration, a full 41% said that they're interested in moving to open source models to help control costs. Now, one really interesting thing about this study that is maybe a little bit different than what we saw in the enterprise sphere is what they're trying to get out of their AI usage. By far the most tracked ROI category was productivity gains. 75% of organizations are measuring the impact of AI by looking at productivity gains. Another 51% are looking at cost savings. That compares to just 20% who are considering revenue uplift. Now, this is different than what we saw with the recent KPMG quarterly pulse survey that found 46% of big enterprises equally split between thinking about productivity and efficiency as a goal of AI and revenue growth and new opportunities as a goal of AI. I think that this reflects the fact that many of these companies are just a couple years old. And whereas those legacy players have much more room for business model disruption and transformation, these companies are just finding their business model for the first time. They're not in the transformation and disruption mode. But what they are is looking to do whatever it is that they're doing more effectively. Budgets for internal AI productivity are set to nearly double in 2025 with companies spending on average between 1 and 8% of total revenue on it. And one really important note that I thought was fascinating and super reflective of what we're seeing in the enterprise space as well is that the budget for that internal productivity AI is increasingly coming from existing areas like R&D and business units but not from some innovation budget. Between 24 and 25, the percentage coming from innovation budget went from 47 to 23% reflecting I think the move again away from the experimentation phase into the full deployment phase. Fascinatingly, when it comes to the biggest challenges for deploying AI for internal uses, finding the right use cases was listed as the top challenge. 46% of respondents ranked finding the right use cases as a top challenge for model deployment for internal use cases. To shill aggressively for a minute, this is exactly why we designed the agent readiness audits. No one wants to spend a bunch of time figuring out what exactly to use these tools, which are so clearly so powerful for. They just want to be able to use them to get value. It's why we try to hack down the time to use case discovery in order to have people spend more time just getting that actual value. Now, maybe unsurprisingly, the more companies use AI, the more use cases they find. For companies that had greater than 50% of their employees actively using AI tools, they had an average of 7.1 different use cases. The most popular use cases are probably what you'd imagine. Coding assistance at 77%, content generation and writing at 65%, documentation and knowledge retrieval at 57%, product and design at 56%, sales productivity at 45%. One that might be a little bit lower than you think is customer engagement and customer service which had 42% listed as a top use case. But once again, I think that reflects a slightly different demographic of companies rather than it being not actually that popular. In other words, these companies are very very young in their life cycle. They tend to have less sophisticated customer service organizations. And I think that probably explains more why they are deploying that use case less frequently. And when it comes to which use cases are having the biggest impact in terms of productivity, the vast majority are seeing productivity gains between 15 and 30%. Coding assistants on the other hand was by far the top ranked use case when it came to impact on productivity. In fact, for those high growth companies, an average of 33% of their total code is currently being written by AI. So more than what we've heard from Google and Microsoft. But across all the other companies, even the ones that aren't high growth, 27% of their code is being written by AI, this is just so clearly the biggest breakout use case so far and one that's having a huge impact right now. One area that continues to be an area of experimentation is around the pricing model. 36% of companies are still using primarily a subscription or seatbased model as opposed to just 19% who are usage based or 6% who are outcome based. But hybrid is now the most popular category at 38%. I expect that we're going to see a lot more experimentation with business model and we're going to see that usagebased and outcomebased number come up. In fact, 37% of respondents said that they do plan to change their AI pricing model in the next 12 months thinking about things like consumption and outcomebased pricing as well as factoring in ROI. Now, one section of this report which really I can't do justice to as a podcast but which you should absolutely spend some time with is the section titled AI builder techstack. This is where they look across every different domain which tools companies are using. So for model training and fine-tuning, LLM and AI application development, monitoring and observability, inference optimization, model hosting, model evaluation, data processing, vector databases, synthetic data, DevOps and MLOps, product and design. If you are trying to build out your company's tech stack, go look at what the builders are actually using. couple that I want to call out. At least at this stage, the coding assistance is a two-man race between GitHub Copilot, which had nearly threequarters of development teams using it, and Cursor, which is absolutely coming up on their heels with 50% of respondents already using it. We recently saw how Amazon developers are lobbying them to get rid of their internal tool and just use cursor instead. Seems like that is happening more broadly as well. One that I wanted to call out though, because it's something that we've talked about a bunch on this show recently, is around model evaluation. When we were talking about the AI engineering world's fair, we talked about how eval are a growing topic of conversation among the builders, but how it's still really lagging behind in a way that seems almost destined to grow in focus in the coming months. That is certainly the case even among the builders. The key takeaways from the survey around model evaluation were that there was no clear standalone leader. In fact, 20% of respondents didn't know which tool they use for evaluation and around a quarter admitted to either not knowing or not having a tool in place. That is absolutely going to change and represents a huge opportunity for both companies to build evaluation tools as well as for companies to get ahead of their competitors by being better at evaluation. If you're looking to invest in an area to stand out, that is something to consider. Speaking of standing out, the last section of the report is a look at some of the key trends across different internal productivity use cases. And the biggest takeaway that I would say is that the incumbents really do have an advantage. For example, in sales productivity, one of the key trends was many teams are getting their AI powered sales features straight out of Salesforce, indicating that an easy path is to lean on your existing CRM's built-in recommendations, forecasting, and opportunity scoring rather than bolt on a separate service. In marketing automation, they write, \"Marketers overwhelmingly turn to Canvas generative features for onbrand visuals and quick content iterations, making it by far the most common AI touch point in the marketing stack. In customer engagement, teams overwhelmingly rely on Zenesk and Salesforce's embedded AI features for customer interactions, signaling that ease of plugging into existing ticketing and CRM workflows still beats adopting a standalone conversational AI platform. where there is more flexibility and exploration of new solutions comes in areas which if not being totally new are so different in the world of AI that it really opens up new opportunities like knowledge retrieval and documentation. Still, it really does bring up just how challenging it's going to be for all these vertical AI companies who have to compete against these legacy platforms that have such entrenchment even among the startups themselves. There is a ton more in this report and I really think that especially if you are in an enterprise who is trying to gut check and understand where you sit and how your adoption is going. In addition to looking at the enterprise focused surveys, go check out this builder report. In some areas, it will probably scare you with how far ahead they are relative to agent deployments. But in other areas, they're struggling with some of the same things. Helping employees figure out how to actually use these tools, for example. It's a confirmation of both how fast the industry is moving, but also that we're all in this together and that even for the companies who are building the technology, much of these transformations are incredibly, incredibly difficult. As I said, I will include the link to this report down in the show notes. Big ups to Iconic for producing this. I think it's super valuable. And thanks, of course, to you guys for hanging out. Till next time."
  },
  {
    "id": "sd62iH8OfxA",
    "title": "Zuck's Superintelligence Lab Is Official",
    "published_at": "2025-07-03T11:20:36Z",
    "description": "Meta has officially launched its Superintelligence Lab with Alexander Wang named Chief AI Officer and Nat Friedman joining the effort. The team draws top talent from OpenAI, DeepMind, and Anthropic, with a focus on developing next-generation AI models.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 541,
    "views": 2075,
    "likes": 76,
    "url": "https://youtube.com/watch?v=sd62iH8OfxA",
    "transcript": "Welcome back to the AI Daily Brief headlines edition. All the daily AI news you need in around five minutes. Nothing like having a daily show, right? Where the second you press stop on recording, there is news that makes your last episode out of date. If you are our daily listener, you'll know that yesterday we talked all about the latest in the talent war between OpenAI and Mark Zuckerberg. And literally just an hour or something after I pressed send on that thing, Zuckerberg super intelligence team was officially announced. So, here we are doing the catch-up on that. In a memo to staff on Monday, Zuckerberg introduced his new AI hires and revealed the official name of the new division. He wrote, \"As the pace of AI progress accelerates, developing super intelligence is coming into sight. I believe this will be the beginning of a new era for humanity, and I am fully committed to doing what it takes for Meta to lead the way. We're going to call our overall organization Meta Super Intelligence Labs, or MSL. This includes all of our foundations product and fair teams as well as a new lab focused on developing the next generation of our models. Now, as we thought, former scale CEO Alexander Wang will be leading these efforts. He will both lead MSL as well as being named chief AI officer for Meta as a whole. Interestingly, when it comes to the labs, he is being joined by Nat Freiedman. Now, you'll remember previously ran GitHub at Microsoft and his investment firm with Daniel Gross is one of the most active and successful AI investors. Alongside the note from Zuckerberg, we also got a list of 11 names, some of whom we haven't seen before, who had joined this new effort. In addition to some ex OpenAI folks who weren't in the initial reporting, we also had a couple others from Anthropic and from Google DeepMind, although the concentration is definitely from OpenAI. Now, in terms of the group's mandate, it's not exactly clear what the balance is between fundamentals research versus product advancement, but it does appear like MSL has a mandate to pursue both. Now, the information, for its part, is fairly skeptical. They write, \"This new or is the product of a massive spending spree by Zuckerberg to snag the best AI talent possible in hopes of turning around Meta's recent AI slump. The end result is a team that, without being too cynical, feels highly combustible. Don't be surprised if at least one high-profile departure occurs within a few months. Any group with a lot of big egos working under intense pressures from a controlling chief executive is going to have trouble staying together. They also noted that Alexander Wang at the helm has never produced a foundation model and is better known for his political savvy than his AI skills. They suggested that he will be more of an adviser to Zuckerberg than a hands-on research lead. Touching on Freriedman, they pointed out that he turned down the leading role and suggested Wang instead. Concluding, they added, \"Add to these wrinkles the fact that Meta has hired a bunch of highly paid scientists from OpenAI who will join existing staffers who are likely feeling a little disgruntled at how things have come about. Meta's AI team has undergone repeated upheavalss over the past couple of years. Meta could be described as a permanent revolution of AI, and that likely won't stop now. Now, in some ways, the whole process looks a little bit more like assembling a sports super team than a traditional tech hiring plan. from sky-high salaries to plucking top talent from across the sector. Sarah Guo from Conviction wrote, \"There are now folks helping researchers negotiate their comp packages and taking a fee like agents for athletes.\" Look, I think it's completely reasonable to be skeptical of this. It is totally understandable to note where the very real possibilities for breakdown are, but at the same time, while dream teams can break down because of big egos, they can also create their own sense of momentum. You have to think that a lot of these folks joined not just because they were getting huge paydays, although that's part of it. They joined because they thought that if they all joined at the same time, there was a real chance that they could be first to this coveted goal. That creates excitement and like I said, momentum that I don't think all these media reports are quite giving enough credence to. It's now in the public eye and we'll see if the spending spree has stopped or if they're still assembling. But Meta's Super Intelligence Lab is here and it is a new force to be reckoned with in the space. Speaking of powers to be reckoned with in the space, Apple seems to be giving up entirely and considering handing Siri over to OpenAI or Anthropic. According to Bloomberg's Mark German, Apple has met with both AI companies to discuss using their models to power the next iteration of Siri. German framed this as a quote potentially blockbuster move aimed at turning around its flailing AI effort. Until now, Apple used their own in-house foundation models to drive Siri and had been planning to continue on the same course for the new version due next year. The exploration of outsourcing the model is still in its early stages, but the labs have been asked to train a special version of their model that can run on Apple's cloud infrastructure. Apple uses their own silicon rather than industry standard NVIDIA chips, so some conversion is necessary. The internal project dubbed LLM Siri remains ongoing. The shift in thinking was reportedly the result of Vision Pro lead Mike Rockwell taking over the project earlier this year. One of the first orders of business was to test Siri using thirdparty technology from OpenAI, Enthropic, and Google. Rockwell and other executives concluded that Anthropics models had the best performance, leading them to open discussions with the company about using Claude. German reports that plans are still murky. Apple has approved a multi-billion dollar budget for running their own models via the cloud, but beyond that, nothing is set in stone. Still, it seems like executives are reportedly on board with outsourcing the model, with Rockwell and others seeing little reason to stick with their own technology. At the same time, morale in the ranks is beginning to sour with German writing, \"Some members have signaled internally that they're unhappy that the company is considering technology from a third party, creating the perception that they are to blame, at least partially, for the company's AI shortcomings. They've said that they could leave for multi-million dollar packages being floated by meta platforms and open AI.\" Signal captured a part of the zeitgeist on this, writing, \"Absolutely astonishing. Apple used to own the full stack, silicon to software to services. Now they're outsourcing the one layer that will define the next decade of computing. It's a metaphysical betrayal of their own DNA. Open AAI and Anthropic don't need Apple, but Apple desperately needs one of them. This puts Apple under the models it's integrating. Wild reversal. Whoever they choose, they now owe existential dependency to. And finally, if consumers realize that Siri does not equal Apple anymore, that it's powered by OpenAI or anthropic, then what exactly is Apple's IP? A thin shell over someone else's mind that kills the aura of vertical magic. Given how frequently Signal shows up as a quote on the show, I often think that their perspective is very valuable. On this one though, I have to disagree entirely. My strategic sense is that even if all this is true, it doesn't matter. Apple has to do something big. They are behind, falling more behind, and they are not catching up with their own models. Period. Full stop. End of story. Think about the first thing we just talked about with his incredible spending spree with Zuckerberg. That's what it takes to compete for talent right now. when Apple's not doing it and gives no indications that they're going to do it. So, they are left with a set of solutions that involve not having that access to talent. That means that this sort of partnership or acquisition like the perplexity acquisition we talked about last week are their paths forward. Yes, it is the case that Apple used to own the full stack, but that is not a strategy that is available to them now. The longer that they cling voriously to what they once were, the more likely it is that they will never be that again. I also think that this perspective understates the value that Apple still brings and overstates consumer recognition. On the latter point, all that the average consumer wants is for Siri to work. If it works, they're not going to care or ask questions about how it works. I think that the brand risk from having it powered by OpenAI or Anthropic is much lower than it might appear from those of us who are watching this like baseball stats. And when it comes to the idea that Open AAI and Anthropic don't need Apple, Apple still has an incredible number of installed devices, billions around the world. getting access to that distribution at a time when models are highly commoditized and getting more so is nothing to sneeze at. Now, OpenAI has ambitions to actually go compete with Apple on its home territory of devices and usher in the post iPhone era, but Anthropic doesn't and they don't have the resources to even consider that. So, in my estimation, Apple should do something like this and they should do it as fast as humanly possible. Lastly today, a little fun feature update for those Vibe and regular coders out there. Curser has launched a web app to manage AI coding agents. The AI coding platform continues to expand their interface beyond the IDE. In May, Cursor launched background agents that are able to take instructions and then work independently of the user. The following month, they introduced a Slack integration allowing users to set the agents to task from within their workspace. And this web app is another natural extension, letting users give instructions via the browser on desktop or mobile. Notably, this is the first time that Cursor has been available on a mobile device without needing to use Slack as a workaround. And at first glance, people love it. Developer Nick Dobos writes, \"Cursor on mobile is here, and it's amazing. Been using it for a few weeks now, and I will never not be amazed to be merging PRs while riding Pelatonin. I'm never touching a laptop again. Just bookmark the website on your home screen, and it's basically an iOS app. I am very excited for that to be a new interface norm going forward.\" And frankly, it just kind of makes sense. If part of the way that we interact with coding isn't sitting there in front of a screen, but is instead interrogating it and using our voice to tell it what to do, that's something that really can be done from mobile. In any case, that is going to do it for our slightly extended version of the headlines. Next up, the main"
  },
  {
    "id": "3DPxhKgsKA8",
    "title": "How AI Eats Consulting",
    "published_at": "2025-07-02T22:47:21Z",
    "description": "OpenAI is hiring forward deployed engineers and building services that overlap with Palantir, Accenture, and McKinsey. The role focuses on embedding technical staff with clients to fine tune models and develop apps, often backed by $10 million deals.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 814,
    "views": 30046,
    "likes": 717,
    "url": "https://youtube.com/watch?v=3DPxhKgsKA8",
    "transcript": "Welcome back to the AI daily brief. One of the categories of firms that has done the best so far in the AI boom is of course the consultants. Revenue for consulting related engagements is way up for all of the biggies like Accenture and McKenzie. In fact, AI is driving a huge portion of their new business. And yet at the same time it feels very very clear that while there is a massive short-term opportunity for consulting right tons and tons of enterprises and businesses that need help navigating this transformation it is also equally clear that AI represents a fairly existential threat to their models as such. To the extent you view consulting as experts with specialized knowledge being smart about how to gather information, process that information and turn that into advice. A lot of that certainly sounds like things that AI and LLM are very good at, right? In fact, some of my episodes about the AI disruption of consulting companies have been my most popular of all time. And what's more, consultants aren't just facing challenges from LLMs directly. To some extent, one of the big patterns that we're observing is that every technology provider is also becoming a services company at the same time. This is the palunteerification of everything and according to the latest from the information openai is among the companies who are walking down that road. Over the weekend the information published this piece openai takes a page from Palunteer doubles down on consulting services. They write openai is adding staff and resources for a consulting like service in which its engineers guide customers through a process known as fine-tuning. Now you guys are a little bit more sophisticated so I'm sure you know what fine-tuning is but basically it's a process of modifying a model based on a particular set of data like the set of data that you have around a particular enterprise or company. The information continues to get the consulting help. OpenAI is typically requiring customers to spend at least $10 million. OpenAI is telling potential customers that it will refine its models such as GPT40 using their proprietary corporate data so that the model can solve problems specific to their needs. These engineers also develop applications powered by customized models such as chatbots akin to chatgbt according to openai executives and customers of the service. Now the information says that this move puts OpenAI into quasi competition with software firms like Palunteer, consulting firms like Accenture and they also point out that from the very little that we know, this appears to be part of how ex OpenAI CTO Mirror Moradi startup which of course raised a $2 billion seed round on a $10 billion valuation looks to stand out and compete. Again, from the information, thinking machines lab plans to use reinforcement learning, a common AI development technique that rewards an AI model for accomplishing certain goals and penalizes it for other behaviors. TML plans to customize models on specific business metrics its customers track, aka KPIs, which typically relate to revenue or profit growth. TML may be banking on the idea that customers of AI may be willing to pay a premium for models customized for their industry. Now going back to the OpenAI version, the company has specifically been hiring for a role known as forward deployed engineers. They say that OpenAI formed an FTE team earlier this year and hired around a dozen people for it, including several who work for Palunteer. Now, forward deployed engineer is perhaps the hottest job title in Silicon Valley right now. And to understand what it is, go back and check out a post from the Palunteer blog back from November 2020 called a day in the life of a Palunteer forward deployed software engineer. It followed a day in the life of Brian who was at that time focused on delivering data integration solutions to a US Department of Defense customer. Brian said, \"A forward deployed software engineer is a software engineer who embeds directly with our customers to configure Palunteer's existing software platforms to solve their toughest problems. While a traditional software engineer or dev focuses on creating a single capability that can be used for many customers for deployed engineers focus on enabling many capabilities for a single customer. We are deployed across many industries and problem domains. So the breadth of projects we tackle is large and always evolving. When asked is an FTE similar to a consultant. Brian said no not really. I think one of the things that differentiates us from consultants is how technically creative we can be while also delivering solutions quickly. In the hands of a forward- deployed engineer, Palunteer's products are ready built playgrounds that empower us to be flexible and efficient in how we solve problems. Unlike consultants, we can pull most of the pieces together out of the box, meaning we don't need to reinvent the wheel for each customer and spend years creating a patchwork solution. Instead, we can focus on composing the right architecture of features or whipping up a new secret sauce to supercharge users. This way, I'm always creating software that makes my customers more uniquely able to do their jobs. Now, as much as Brian and Palanteer said that forward deployed engineers are not like consultants, they are absolutely undeniably a new category of consultant. And the category and what makes it interesting is that they are specifically focused on a particular software platform and fast forwarding and making it work inside a company at a more rapid clip. And so going back to OpenAI once again, the idea is basically that there are some advanced technical things that you can do with these models that might make them more performant for a variety of enterprise use cases that frankly most enterprises just aren't going to have the technical capabilities to do or at least do well. And so by embedding engineers directly inside their biggest customers, they make their solutions more usable. Now this is a major trend right now across the AI industry. When Palanteer first started doing this, there was skepticism from Silicon Valley, who has a near visceral counter reaction to anything that hints of services and not software margins. And there was even skepticism in the public market. However, now as Palunteer is trading as one of the most expensive, if not the most expensive major stock in the market, things have shifted dramatically. What looked like smaller margins than pure play software companies has instead turned into a significant advantage and a deep entrenchment that owns the customer relationship. This trend has become prevalent enough that at the beginning of June Andre Horowitz dropped a research post called trading margin promote while the forward deployed engineer is the hottest job in startups. The post reads for the better part of the last decade it's been broadly assumed that productled growth or PLG is superior to implementationheavy enterprise software. The allure is obvious. PLG promises greater scalability and higher margins. The obsession has been driven by success stories like Atlassian, Slack, Figma, Notion and Dropbox and more recently chatbt and cursor. All of these products offer simple single player modes, are easy to adopt without needing a sales call, and can be purchased directly with a credit card. No lengthy scoping or enterprise contracts required. During platform shifts, however, companies have room to experiment and build more intricate products that don't follow the standardized formula. Salesforce, Service Now, and Workday did this during the transition from on-remise to cloud platforms. Each of these companies sells an enterprise platform requiring significant implementation, services, and support, which is the antithesis of bottoms up PLG. However, in nailing complex implementations, these companies achieve dominance with impressive market capitalizations. Their combined value dwarfs that of the top PLG companies, and it's not even close. He continues later on, \"Category defining companies like Salesforce and Service Now became indispensable largely because of their ability to integrate with a company's internal systems and context.\" The customization effort initially results in lower gross margins and higher burn rates. At IPO, for example, Service Now's gross margin was 63.2% 2% and work days was 54.1% far below the ideal around 80% per software. Even Salesforce, generally considered the gold standard, reportedly burned over 52 million to generate 22 million in revenue before developing its partner ecosystem. These complex businesses are easiest to build early in a platform shift when workflows are still taking shape and the payoff for replacing an entire system of record is highest. The AI platform shift is different from and in some ways more exciting than the previous transitions to cloud or mobile though because the implementation work required to make agentic experiences can itself be streamlined and automated by AI. Historical integration work might require outreach and collaboration with partners, mapping data fields, navigating data transfer between different coding languages and understanding various internal guidelines. This is the kind of work that can now be done more efficiently and in some cases entirely with AI. Once those workflows and behaviors are established, these companies possess modes that allow them to increase prices and build implementation ecosystems. Now, he goes on with a bunch of different observations and best practices. But the point is this is an instantiation of something that is absolutely a trend that everyone is seeing, which is that all of the big players have some version of this approach to FTEEs and actually building on these new platforms for the enterprise clients. But what does this mean in terms of OpenAI strategy? The line that I don't totally agree with is the idea that it puts OpenAI into quasi competition with Palunteer and Accenture. Although that is nominally true, it's pretty clear to me as a fairly close observer that OpenAI one is going to do whatever it takes to continue to grow adoption of their tools and two has a strong sense that owning the customer relationship is really going to matter. All the indications we see from OpenAI with things like building their own agents indicates that they are not comfortable betting exclusively on model superiority and want to actually own the relationship with the end customer. Now when it comes to consumers in chat GBT they have that in spades. When it comes to the enterprise that's still more up for grabs even though they are in the lead. But at the same time it's very clear to me that OpenAI is not doing this all on their own. For example, over the last couple of months, they have announced a number of partnerships with dev shops and implementation labs like Tribe AAI. In May, they announced the Tribe partnership. And just a week ago, they announced a similar relationship with Fractional. The idea is pretty simple. OpenAI brings the models. Fractional or Tribe or other partners bring, as Chris Taylor, the CEO of Fractional, put it, the endto-end support from idea to production. And what's more, OpenAI isn't just partnering with the upandcomers. They have relationships like this to some extent with basically all of the big gsis or systems integrators including for example this one with PWC. So when it comes to OpenAI I see this more as them doing everything it takes and a validation of for deployed engineers as a key part of the playbook than as them having some radical new strategy. But it still does have the impact of putting new pressure on the existing consulting partners. And we're starting to see that manifest. Bloomberg recently reported that PWC's AI head had said that the firm had started to cut prices because tech was saving their staff time, said chief AI officer Dan Priest in an interview with Bloomberg. Clients would hear us talking about using AI and say we want our fair share of those efficiencies. We certainly, as appropriate, give our clients the pricing benefit of the efficiencies we're achieving. In other words, hold aside the details, there is downward price pressure that AI is creating for these companies that are selling AI services. Again, to bring our own personal examples of this, one may still absolutely prefer the comprehensiveness and human touch that you get working with a PWC or an Accenture or Mackenzie or whomever, but what we do with our agent readiness audit, interviewing dozens or hundreds or even thousands of people over the course of a couple of days and turning that all into actionable insight around which agent use cases are best suited for your firm based on the hundreds of hours of interviews that we just got would have been completely impossible in the pre-AI era. And even the closest approximation of it would have cost hundreds of thousands of dollars and taken months. We're offering it for less than a tenth of that in days. And if we're taking out the discovery portion of what consultants have historically done, other companies are nibbling at all the other parts as well. Now, as an aside, by the way, in our experience, as much as they have to charge for discovery work, it's not the work that consultants want to do. Consultants and professional services firms want to do the highv value stuff that actually produces results that gets them rehired, not just the long laborious discovery. And so it's actually a good fit and a win-win for everyone. But the point is AI is absolutely coming for a lot of what is on the books as revenue right now. The den of conversation talking about the disruption to consulting is doing nothing but getting louder. Last week the economist ran a piece called who needs Accenture in the age of AI. They write between the start of 2015 and the end of 2024 Accenture which split off from its accounting sibling in 2000 and went public a year later generated a total return of around 370%. handily outdoing not just the S&P 500 index, but also Goldman Sachs and Morgan Stanley. As America's stock market climbed to an all-time high in February, the firm was worth 250 billion, more than either investment bank. Since then, however, investors have wiped out some 60 billion from its market value. They pointed out that new bookings for both one-off consulting projects and managed services were down, and that while some of it was a temporary setback, think trade war, real war, and all the other macro problems, as The Economist puts it, the firm's problems run deeper. Having made a fortune telling others how to adapt to newfangled tech, it now faces the self-same predicament in the age of general artificial intelligence. As semi-autonomous geni agents sweep the world, who needs consultants? Now, obviously, I think that there is a lot of room for evolution and adaptation. But like in almost every industry, the reality is that consulting and professional services will not look the same in a year or certainly 5 or 10 years as it does now. The companies that are able to nimblely adapt to that and change could build incredible enduring legacies, but they're going to have to do it with people coming in from all sides. Software companies, Neo consulting companies, product companies, everyone, it seems, is now in the business of technology and services all at once. And that could be a challenge for now. Very interesting to see that OpenAI is moving into this forward deployed engineer space and we will continue to keep an eye on the trend. Thanks as always for listening or watching."
  },
  {
    "id": "mLBsAymN3xk",
    "title": "The Latest on Fair Use in AI Training",
    "published_at": "2025-07-01T20:00:42Z",
    "description": "A federal judge has ruled in favor of Anthropic, deciding that AI training using copyrighted books is fair use, at least for now. This episode breaks down what the ruling means, why it’s a partial win, and what’s next as the case continues.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 519,
    "views": 1379,
    "likes": 56,
    "url": "https://youtube.com/watch?v=mLBsAymN3xk",
    "transcript": "Welcome back to the AI Daily Brief headlines edition. All the daily AI news you need in around 5 minutes. We kick off today with a fairly big victory for Anthropic in their copyright case as a federal judge rules that AI training is fair use. Now, Anthropic is one of the many AI labs that are fighting with authors and publishers over their use of copyrighted works and training data. Each lab is running effectively the same argument that AI training is analogous to reading and is therefore not a breach of copyright under fair use provisions. A federal judge has now accepted that argument, handing anthropic and early victory in the case. Christina Frohawk, a professor of legal writing at the University of Miami School of Law, explained, \"The court treats the AI as akin to a human learning from copyrighted material. It's fair use if you and I pick up a book and read it and develop our own thoughts.\" She said, \"The court came to the same conclusion about AI models.\" In handing down the ruling, the judge commented that the quote author's complaint is no different than it would be if they complained that training school children to write well would result in an explosion of competing works. He noted that copyright law quote seeks to advance original works of authorship, not to protect authors against competition. Now, all that said, this is only a partial victory for Anthropic. The order was only decided on this extremely narrow piece of law with a further dispute in the case going to a separate trial. That trial will deal with what Anthropic refers to as their central library, a corpus of all the books in the world used to create training data sets. As well as scanning in physical books, plaintiffs claim Anthropic pirated 7 million digital copies to create this repository. In a prelude of what's to come, the judge wrote, \"This order doubts that any accused infringer could ever meet its burden of explaining why downloading source copies from pirate sites that could have been purchased or otherwise accessed lawfully was itself reasonably necessary to any subsequent fair use.\" According to the copyright law, willful infringement can carry a maximum penalty of 150,000 per work. If the court rules that Anthropic breached copyright millions of times in pirating books, the fines could easily bankrupt the startup. The judge noted that the fact that quote, \"Anthropic later bought a copy of a book it earlier stole off the internet will not absolve it of liability for theft, but it may affect the extent of statutory damages.\" One of the interesting points to note is that the fair use ruling was based on anthropics AI outputs being transformative. That is, the AI model wasn't capable of directly reproducing copyrighted works. It was trained to create something new out of its training data. In fact, the judge referred to Claude's outputs as exceedingly transformative, noting like any reader aspiring to be a writer, Anthropic LLM trained upon works not to race ahead and replicate or supplant them, but to turn a hard corner and create something different. So ultimately, Anthropic is far from off the hook and the law is far from settled, but it is still a landmark ruling for the AI copyright question. Importantly, this is only a ruling in federal court, so it isn't binding in other cases and could still be appealed. However, it can be used to persuade other judges to follow this interpretation of the law for the time being. Obviously, this is and remains a contentious area, one in which I fully anticipate we will need to have end up before the Supreme Court before we actually finally know how it will be handled. Next up, staying on the law train for a moment, Sam Alman is fighting the IO lawsuit on X. The legal battle surrounding Johnny Ives AI device startup and the identically named Google spin-off is starting to get a little bit nasty. Lawsuit filings are now circulating, but Sam Alman decided to take his version of the story direct. Yesterday, he posted, \"Jason Ruggo had been hoping we would invest in or acquire his company, IO, I yo, and was quite persistent in his efforts. We passed and were clear along the way. Now he is suing OpenAI over the name. This is silly, disappointing, and wrong. I made a lot of time to talk to Jason on his repeated outreaches because I like helping founders. A few days before the lawsuit, he asked again for us to acquire his company even after we tried to pass just before. It is cool to try super hard to raise money or get acquired and to do whatever you can to make your company succeed. It is not cool to turn to a lawsuit when you don't get what you want. Sets a terrible precedent for trying to help the ecosystem. All that said, I wish Jason and his team the best building great products. The world certainly needs more of that and less lawsuits. OpenAI's legal filings, meanwhile, tell basically the same story. That technical staff at IO, this new OpenAI division, met with Ruggo out of a sense of professional courtesy, were unimpressed with a broken demo, and moved on to build something other than what they had seen. In Rugolo's responses on Twitter, he basically said it was about the name. In one post, he wrote, \"There are 675 other two-letter names that they can choose that aren't ours.\" And basically, if you want to read on how the community thinks about this, I think that on the one hand, after Sam shared these emails, the OpenAI side of the story that they just weren't all that impressed looks pretty resonant or at least true from what they were discussing internally. But at the same time, people also kind of feel like, hey, did you have to choose a name that close? Ultimately, my guess is that it's not worth the trouble and OpenAI just changes the name. But what do I know? One more interesting thing on OpenAI. The company has quietly designed a productivity suite for chat GBT which could put them in direct competition with big backers like Microsoft. The features would allow users to collaborate on documents and communicate with each other similar to the functionality of Microsoft Office or maybe even more directly Google Workspace. The information reports that no decision has been made about launching the feature, but a release could drive a further wedge in OpenAI's relationship with their backer Microsoft. In some ways though, this is just a natural extension of the canvas feature, which gives users a separate document window inside chat GBT, making the assistant more useful in work settings. It would also allow OpenAI to compete to be an everything app. Coincidentally, we got news earlier this week that XAI is working on a productivity suite as well. So, is this some big competitive change or is it just that all of these products are trending towards the same direction and are going to have some similar features? I tend to think it's more that than any sort of big new competition between these two frenemies. Last up, a couple of product updates before we get to the main episode. First, Air Table have made a major move, relaunching as an AI native app. CEO Howy Lou posted, \"Instead of just adding more AI capabilities to our existing platform, we treated this as a refounding moment for the company. We started with a clean slate imagining of the ideal form factor for building apps in the agentic era. The no code database platform is now a fully functional vibe coding app as well. Users can now use natural language to prompt apps into existence while integrating them into Air Table's production ready components. Lou gave the examples of creating a VC deal tracker that does automated company research or a marketing campaign manager that monitors all relevant competitors. The AI integration also means you can easily run queries across your database. For example, you can get the assistant to crunch thousands of support tickets to find common pain points quickly. The rebuild also adds agentic functionality built in to help you manage large data workflows. Howie wrote, \"When the cost of making and continually evolving apps drops to zero, everything changes. Companies will build exactly what they need rather than settling for rigid off-the-shelf software. The new default is AI generated apps plus built-in AI agents working 24/7. What's needed in this new era is a new form factor and paradigm for software, the AI native app platform. This is the new Air Table. And what's launching today is just the beginning. We're excited to release a slew of new AI powered capabilities in the months ahead. Sneak peek generate any visualization agents leveraging MCP agentically sourced data sets and much much more. Another company getting all agentic is 11 Labs who have launched a new voice AI assistant called 11 AI. The pitch is that this voice assistant has full MCP integration so can pull data from services including Perplexity, Slack, Gmail, and Google Calendar. You can even connect your own MCP server so the assistant can theoretically access anything you want it to. Functionally, this is pretty similar to the voice assistant that Anthropic announced earlier last month alongside the launch of voice mode. It's designed as a voice interface to access all sorts of AI functionality. The advertising is even similar. Anthropic advertised their product as being able to help power a young professional through their morning, while the 11 Labs ad followed a similar story, but featuring a young man rolling out of bed with 5 minutes to spare until a web conference with his boss. The assistant helped him delay the meeting over email, order a greasy breakfast, and remember what his boss's pet is for small talk. The release came alongside the long-awaited mobile app so you can chat to 11 Labs assistant on the go. Now, I'm not sure about the positioning of these assistants. I am a little more skeptical than most of these sort of generalist consumer assistants, but I could be very wrong. But still, once again, if some of the theme of the OpenAI productivity suite is the convergence of all of these platforms into one common set of features, this is yet again another example of that. Anyways, that is going to do it for today's AI Daily Brief headlines edition. Next up, the main"
  },
  {
    "id": "6o8IHZJEzxM",
    "title": "Anthropic Starts Tracking AI's \"Economic Fallout\"",
    "published_at": "2025-07-01T12:11:06Z",
    "description": "Anthropic is launching the Economic Futures Program to measure the impact of AI on jobs and the economy. The company will fund new research, host policy forums, and establish long-term tracking mechanisms for AI’s impact on employment.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 454,
    "views": 4000,
    "likes": 104,
    "url": "https://youtube.com/watch?v=6o8IHZJEzxM",
    "transcript": "Welcome back to the AI daily brief headlines edition. All the daily AI news you need in around 5 minutes. We kick off today with a new program from Anthropic. The initiative is called the economic futures program and in short it seeks to support research on how AI is impacting employment and the broader economy. The goal is also to help develop policy proposals to get ahead of any consequent shifts. Sarah Hec, Anthropics head of policy programs and partnerships, said, \"Everybody's asking questions about what are the economic impacts of AI, both positive and negative. It's really important to root these conversations in evidence and not have predetermined outcomes or views on what's going to happen.\" Now, if you are a regular listener to this show, you will know that Anthropic CEO Dario Amade has long been of the view that AI labs have a responsibility to participate in the policy discussion and also has been increasing the volume of his warnings about potential job displacement and workforce disruption over the past few months. His most stark warning came in May when he predicted that AI could wipe out almost half of entry-level white collar work and could drive unemployment as high as 20% over the next 5 years. In January while discussing the possibility of a post-work society he said I think AI companies are going to be at the center of that or in the crosshairs of that and we have a responsibility to have an answer there. So this new initiative has three pillars. First anthropic will hand out research grants to further academic work on the topic. Second they also intend to create forums for researchers, policy makers and AI practitioners to come together for policy discussions. Finally, the company wants to scale their AI economic index to create longitudinal data sets that track AI's economic usage and impact. Another way to think about this is Anthropic trying to drive the policy discussion around jobs in AI to something that is a bit more evidence-based. Sarah Hec again commented, \"I think the key goal is to figure out what is actually happening. If there is job loss, then we should convene a collective group of thinkers to talk about mitigation. If there will be huge GDP expansion, great. We should also convene policy makers to figure out what to do with that. I don't think any of this will be a monolith. Interestingly, given how historically job losses from new technologies have tended to be bluecollar first, one of the interesting dimensions of AI is the first places that some of this is showing up seem to be in the industry that's creating the technology in the first place. DOSs of Menllo Ventures wrote, \"There's a deep malaise in tech right now. New grads can't find jobs. Big tech middle managers are trying to justify their existence. Everyone not in AI wants to be in AI. Founders struggling with their startup for years see Roy rewrite the rules. In that one he's referring to Roy from Cluey who is basically going virality first product second. Dee continues combat security is at an all-time high with the meta offers. In other words, why am I working so hard? Tech Net of AI is just not as sexy a job as it used to be 10 years ago. He did caveat. Of course, this is a massive generalization, but a majority of the conversations I've been having seem to reflect this. Still, while all of that might be true, DD even points out that this is all just anecdotal right now. And when it comes to making policy, the discussion would likely be improved if we had real data about actual layoffs. For example, Microsoft slashed several thousand jobs earlier this year, largely for middle management and software engineering. They could be AI related layoffs, or they could simply be a purge of excess headcount due to a deterioration in economic conditions. The distinction changes the policy implications dramatically. Now, if you are interested in these topics, Anthropic is fielding applications for grants to be issued in August and seeking submissions for symposiums to be held in Washington and Europe this fall. Next up, Meta is turning to private capital to fuel their AI buildout. The Financial Times reports that Meta is looking to raise $29 billion from private capital firms to fund their data center approach with the reporting that they are in latestage talks with some of the largest players in the space including Apollo Global Management, KKR, Brookfield, Carile, and Pimco. Meta is apparently looking to raise 3 billion in equity alongside another 26 billion in debt. If it comes together, this will be one of the largest private capital raises in history. And sources say that Meta could even seek more capital once this round is closed. Meta is working with Morgan Stanley to structure the deal and sources say there's been an exploration of ways to make the debt more easily tradable once it's issued. Now, if you're wondering if it is usual for a big tech company to take on private capital in this way, the short answer is that no, it isn't. But the AI buildout is obviously no regular capital cycle. Meta recently upped this year's capex forecast to around 70 billion, a 10% increase on what was already the most capital intensive year in the company's history. The takeaway of this is that even the largest companies in the world are starting to run up against the limits of public equity to fund these mega projects. Now, of course, we've already seen AI startups take private capital to fund infrastructure. Open AAI and SoftBank Stargate project is already courting private investors using a debt funding mechanism more typically used in the oil and gas industry. And more recently, XAI tapped Morgan Stanley to help them market 5 billion in debt. On the other side of the deals, private capital firms like Apollo are increasingly pitching large companies on these deals as an alternative to corporate bonds. The private equity giants now own major insurers and annuity providers, so need a steady supply of high-quality loans to put on their books. As the deals are often structured as special purpose vehicles or joint ventures, they also serve to keep the debt off the balance sheets of the tech firms. You remember on Friday when we talked about how Goldman Sachs has revised its opinion that we were at the end of the capex cycle to now they believe that we are actually in the middle of that cycle and this would seem to be evidence of that. Lastly today a super cool one that I hope we will expand into a full episode at some point in the future. AI video platform Runway plans to launch a world first generative video game platform. This is a tiny first step in a vertical that seems entirely inevitable. That is of course AI games that can be generated on the fly. Alex Heath of the Verge was given access to the platform called Game Worlds which Runway plans to make available as soon as this week. He writes, \"The consumerf facing product is currently quite bare bones with a chat interface that supports only text and image generation, but Runway says that generated video games are coming later this year. Runway is also in talks with gaming companies about both using its technology and accessing their data sets for training. So then at the moment the platform seems to be basically textbased adventure games with generated still images attached. It's unclear how much of the gameplay is generated on the fly or if the experience is just about generating visuals and text to flesh out a prescripted story line. Users will be able to create their own text and image game in the same style. The consistency of which is a whole technical challenge on its own. Regardless of where they are starting, Runway's ambition is very clear. The company is already talking to TV and movie studios. The recently aired Amazon show House of David was made in part using runways technology and they say that they're working with quote pretty much every major studio and most of the Fortune 100 companies now looking to take on the gaming world. CEO Christoal Valenuela said if we can help a studio make a movie 40% faster, then we're probably going to be able to help developers of games make games faster. They're waking up and they're moving faster than I would say the studios were moving 2 years ago. Look, I think like I said that this is a completely inevitable thing. Generative games are such a natural extension of many of the types of gameplay experiences that people already love now where you can customize your experience and really choose your own adventure that it's really just going to be constrained by what the technology can do. One last interesting note from the Verge piece about this new launch. Heath writes, \"Naturally, I couldn't let Venuela get off our Zoom call without asking him about his recent acquisition talks with Zuckerberg. This is something that we reported on last week as well,\" said Valenuela. I think we have more interesting intellectual challenges being independent and remaining independent for now."
  },
  {
    "id": "-jONvnuVLyE",
    "title": "How the War for Talent Will Shape AI",
    "published_at": "2025-07-01T01:06:46Z",
    "description": "The talent war between Meta and OpenAI is intensifying. Meta is handing out massive offers, some rumored at $100 million, as Mark Zuckerberg tries to build a super intelligence team.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 645,
    "views": 2960,
    "likes": 91,
    "url": "https://youtube.com/watch?v=-jONvnuVLyE",
    "transcript": "Welcome back to the AI daily brief. Today we are talking about some big updates in this incredible talent war story that has been emerging over the past few weeks that of course has Meta and OpenAI at the center of it. The specific context for today's story is that OpenAI has felt the need to actually recalibrate some compensation. They're very clearly acknowledging the pressure that Meta is putting on them. But the reason that I think that this matters for all of us here, and I just want to lay this out right up front, is that while it would be tempting to write this off as something that doesn't really matter to you until it manifests in the technology that actually gets built, there are a couple reasons why I don't think that's exactly true. The first is with a technology this powerful and that has this much force to shape society, who builds it and who profits most from it will have an impact on how the whole thing plays out. Now, perhaps one could argue that everything is so likely to be commoditized that it doesn't really matter because all of these companies will win, and that's at least a reasonable take, but we don't really know what AGI and super intelligence are going to look like, how fast they're going to accelerate once they're here. And so, I think engaging with the question of who is bringing these things into the world is kind of an important conversation for all of us to be a part of. The second reason why I think it matters for us to be paying attention to this is that if there is one watch word for AI in general, it is unprecedented. Everything about this technology, the speed with which it is developing, the rapidity with which it is being adopted, it is just unprecedented. And while yes, for decades we have highly rewarded, very valuable engineers, the changes that this talent war is bringing in terms of expectations for compensation and the value of top talent are unlike anything we've ever seen with talent before. Period. Full stop. Now, by way of background, a few weeks ago, we started getting reporting that Mark Zuckerberg was personally out recruiting a new super intelligence team. It started around the time of the semi-acquisition type thing of scale which brought their CEO Alexander Wang into the metapold to lead this new team. And when that story came to light, reporters also found that it was just the first move of this larger talent recruitment drive. Next, we got reports that there were these crazy offers being thrown around up to $100 million signing bonuses, for example. That was the number that captured everyone's attention. as part of a strategy I think to combat that. Sam Alman seemed to confirm it in a way that I think was meant to paint both Zuckerberg and anyone who took that offer as completely mercenary. And going back to the point that I was making before, perhaps not the type of people that you want in charge of this incredible technology. Now, at the time, and again, this was just a couple of weeks ago, Albin proudly stated that so far no one had taken that offer, but that wasn't going to be the case for long. Last week, news broke that Zuckerberg had successfully poached effectively the entire OpenAI Zurich office. Hyperbolic Lab CTO Euchen Jinn wrote, \"They don't even want to wait for their OpenAI equity to vest. Wonder how big Meta signing bonus is.\" Now, one of the people who was recruited, Lucas Buyer, did also say that the reports of $100 million signing bonuses were fake news. But still, people wondered. By latest count, Meta has successfully poached at least eight OpenAI researchers, and the number seems to be rising. Chubby on Twitter writes, \"Even OpenAI employees confirm the extent of the loss of researchers to Meta. They reposted something from Changu who wrote,\" not too many people outside the company know how talented and hardcore they are. Such a huge loss for OpenAI and I feel really disappointed that the leadership didn't keep them. Now, the reason that Chubby posted that as a screenshot and not as a tweet is that the tweet itself was deleted very quickly. And now we have this new report from Wired. It's called OpenAI Leadership Response to Meta Offers. Someone has broken into our home. Sean, better known as Swix, writes, \"Wow, this Meta OpenAI talent war has resulted in one, going from, oh, the good people don't leave,\" to, \"Someone has broken into our home and stolen something.\" Two, a oneweek company shutdown. Three, pivoting the product launch calendar and AGI race, especially when Stargate comes online. And four, for some reason, Meta is ignoring Anthropic. Now, Sean caveats, of course, if this source is true, but it definitely feels like something big is going on. The specific genesis of the wired piece was that Mark Chen, chief research officer at OpenAI, send what they called a quote forceful memo to staff on Saturday that was basically a battle declaration. A pledge to not go quietly into the good night and fight this war for top talent against Zuckerberg, wrote Chen. I feel a visceral feeling right now as if someone has broken into our home and stolen something. Please trust that we haven't been sitting idly by. So what does that mean that they aren't sitting idly by? Walt Chen said that he was working with Sam Alman as well as other leaders around the clock to talk to those with offers. He said, \"We've been more proactive than ever before. We're recalibrating comp and we're scoping our creative ways to recognize and reward top talent.\" The note from Chen also included messages from seven other research leaders at the company where they apparently wrote notes to staffers to try to get them to stay. Wrote one leader to their staff, \"If they pressure you or make ridiculous exploding offers, just tell them to back off. It's not nice to pressure people in potentially their most important decision. I'd like to be able to talk to you through it and I know all about their offers. And yet complicating all of this is that apparently there is a broader sense of drain at OpenAI even outside this battle, writes Wired. OpenAI is largely shutting down next week as the company tries to give employees time to recharge, wrote another leader in Chen's memo. Meta knows we're taking this week to recharge and we'll take advantage of it. Try and pressure you to make decisions fast and in isolation. If you're feeling that pressure, don't be afraid to reach out. me and Mark Chen are around and want to support you. They also tried to refocus people on the big battle. We need to remain focused on the real prize of finding ways to compute into intelligence. This is the main quest and it's important to remember that skirmishes with meta are the side quest. And so it's pretty clear that as much as Altman might be correct that OpenAI's culture of experimentation and what he and team members perceive as their increased chance of achieving AGI would be enough to make many of the best researchers stick around. At least for some, money is clearly trumping culture. Now, speaking of culture, the AI cash splash is also starting to cause friction among Meta's existing staff. At an all hands on Thursday, Meta CTO Andrew Bosworth was asked about these supposed $100 million signing bonuses. Talking about Sam Alman statements, he said, \"Sam is just being dishonest here. He's suggesting that we're doing this for every single person. Look, you guys, the market's hot, but it's not that hot.\" Now, obviously this matters because alongside the newly recruited super intelligence team, Meta also has multiple divisions packed with AI researchers that are currently on payroll that they still need to keep happy. Bosworth continued, \"What Alman neglects to mention is that he's countering all these offers, creating a market for a very, very small number of people who are for senior senior leadership roles. That is not the general thing that's happening in the AI space. And of course, he's not mentioning what the actual terms of these offers are. It's not a signon bonus. It's all these different things.\" Bosard then suggested that their efforts are bearing even more fruit than what's been reported so far, saying, \"There are quite a few more in the pipeline that I can't announce or share right now.\" Taking one more dig at Sam Alman, he said, \"Sam is known to exaggerate, and in this case, I know exactly why he's doing it, which is because we're succeeding at getting talent from OpenAI. He's not very happy about that.\" Now, I don't know, to be honest, that is not a particularly strong denial of the $100 million signing bonuses thing. It sort of makes it seem like Bosworth is trying to say, \"Well, guys, that's not actually just for signing bonuses rather than denying the totals.\" And also, he's suggesting that it's for a smaller number of people that Sam Alman seems to be implying, but that still could be offers for a meaningful number of people at these incredibly inflated levels. Whatever the actual numbers are, it is at this point very clear that there is a very expensive and wellplanned poaching campaign going on. The Wall Street Journal reported on the existence of something called the list, a compilation of the most talented researchers and engineers that Zuckerberg put together personally over the past few months. It features PhDs from elite schools like Berkeley and Carnegie Melon that typically have experience at either OpenAI or Google Deep Mind. One recruit that spoke with the journal described Meta's goal as obtaining a transfusion from the country's top AI labs. Interestingly, the article discussed how the tight-knit group of elite AI talent are in many cases swapping notes with each other, planning teamups and also generally figuring out if they should work together at Meta. The recruitment of three researchers from OpenAI Zurich, for example, was reportedly a package deal that forced Meta to sign the entire team. Now, a less discussed angle of this story is that none of these researchers entered the field in hopes of cashing in on a 9-figure offer, at least not primarily. When most of these folks were beginning their PhDs, AI was a niche and fairly unglamorous computer science topic that goes double for specialized areas like speech synthesis where reports are that academic adviserss would often try to steer students away from. Alexi Ephro, a Berkeley professor who has supervised numerous top AI researchers said for my students and posttos the objective was never to do hot things and become a millionaire. The objective is to try to solve cool interesting important unsolved problems. Now, of course, what has happened is that those cool and interesting problems are now some of the most valuable in the world, and Meta has started to pay accordingly. And lastly, of course, how it might shake out the dynamics. When someone asked Euchin Jinn, \"How bad do you think this is going to hit Open AAI in future models?\" They said, \"I view OpenAI more as a product company rather than a model company.\" Now, I don't think it's quite that dramatic yet. I think that there is a successful talent campaign being waged. It's repricing the cost of the most elite set of talent for everyone in the market. This is what markets do. Someone comes in, says, \"We think this thing that used to be worth that much is actually worth this much.\" Gets a bunch of people to come over and join them because they're paying more than everyone else. And either they're wrong and the price resets to where it was, or everyone is forced to pay the same as they are, less they get out competed because the talent gravitational pull. My guess is that no one's going to wait around to see if they're wrong or not, and everyone is just going to pay up. When it comes to OpenAI, however, and their destiny, I think it's way too early to count them out just because there's been a successful recruitment of so far less than a dozen senior researchers. And when it comes to this idea of OpenAI as a product company, not a model company, the reality is that they are doing that. In addition, no matter what, it's very clear if you are watching closely that OpenAI is at least a little concerned about the ultimate commoditization of models and is very determined to keep a close relationship with the end user. A recent story from the information which we will most certainly get into later in the week was titled OpenAI takes a page from Palunteer and doubles down on consulting services that I do not believe is about them losing talent to Meta. It's about their assessment of what it looks like to compete in this very new era. Still, it is interesting times. We are in a very up in the air kind of moment and I'm excited to be here covering it with you guys. For now though, that is going to do it for today's AI daily brief. Appreciate you listening or watching as always and until next time, peace."
  },
  {
    "id": "RexkNwfCkCA",
    "title": "Agent Deployments Tripled Last Quarter",
    "published_at": "2025-06-30T01:26:47Z",
    "description": "Enterprise AI agents are moving past experiments and into real use at a record pace. KPMG’s latest survey of over 130 executives at billion-dollar companies shows full deployments of AI agents tripled from Q1 to Q2.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 575,
    "views": 2599,
    "likes": 81,
    "url": "https://youtube.com/watch?v=RexkNwfCkCA",
    "transcript": "Welcome back to the AI daily brief. Today we return to the realm of enterprise AI deployments. Specifically, how agents are finding their way beyond pilots, beyond experimentation, and into production. KPMG has just released their latest quarterly pulse survey and these are a very useful longitudinal way to track how attitudes and execution around AI and agents has proceeded among big companies. The survey captures the perspective of over 130 sea suite business leaders for companies with over a billion dollars in revenue across the US. In other words, this is a study of some of the largest companies. Now, we have been tracking this for over a year now. And going back to the beginning of 2024, the story was very different than it is now. In those early surveys, there was a recognition that AI investment is necessary, but companies were theoretically hung up on things like ROI or more specifically not even knowing how to measure ROI. Between Q424 and Q125 though, the story became very different. There was a continual increase in the anticipated spend on Genai. But more than that, the last pulse survey showed that the tools that we were paying attention to in early 2024 had become totally commonplace by the beginning of 2025. Between Q424 and Q125, the percentage of workers using knowledge assistance on a daily basis. So think chat GBT jumped from 22 to 58%. In other words, the assistant era of AI had become something of a table stakes. The big story then was enterprises were very clearly moving into agent land. The percentage of organizations that were piloting agents almost doubled between Q4 and Q1 from 37% all the way up to 65%. In other words, fully 2/3 of organizations were piloting AI agents in the beginning of this year. What's more, basically everyone was planning on deploying AI agents even if they weren't piloting them yet. 99% said that they were planning to deploy AI agents. And as I've joked previously, I think that means 1% weren't reading the survey correctly. So what is the story this time around? And in short, it's that agents are moving out of the pilot stage and into production. Now, at first glance, you might notice that the percentage of organizations that were piloting agents was down from 65 to just 57%. The percentage of organizations exploring the possibility of using agents was down from 25 down to 10%. But the story is not about a decrease in agentic interest. It's about the fact that we were moving to actual deployment. agent deployments triple between Q1 and Q2 among these big enterprises from about a tenth of organizations having full deployments of agents to a full third. Another way that KPMG put it was that 90% of organizations are now past the experimentation stage. What's more, there were some interesting findings around what people were using agents for. When KPMG asked how much you were focused on efficiency and productivity versus revenue growth as it relates to their AI agent strategies, 36%, a little over a third said that they were mostly focused on efficiency with some exploration of new revenue opportunities. 18% said that they were mostly focused on new revenue opportunities with some efficiency prioritization. Literally no one said that they were focused entirely on either operational efficiency and cost reduction or on the other end of the spectrum entirely focused on creating new markets and revenue streams. And in fact the biggest slice of these enterprises nearly half at 46% were equally focused on efficiency and revenue growth. Now this is of course super interesting to me as someone who talks a lot about the difference between efficiency and opportunity AI. At least from an intent perspective, it seems like most organizations are at least a little bit paying attention to both. A couple other interesting notes, statements that leaders agreed with about agents over the next 12 months. 87% agreed that agents would prompt organizations to upskill employees in roles that will be displaced. In other words, they anticipate that agents will take over some big chunks of work that will require employees to be upskilled to do other things. 87% agree that agents will redefine performance metrics. 86% believe that agents will enhance job satisfaction by helping manage workloads. And right now, it's worth noting that every survey that comes out, and one can be skeptical of this reasonably, but it is very consistent, shows employers viewing agents as something that makes the work experience better for their people, not just a tool to ruthlessly cut headcount. Maybe the most interesting statement that leaders agreed with was 82% of leaders agreed that in the next 12 months AI agents will become valued teammates and contributors. This really puts a fine point on that idea that we are moving out of the exclusively assistant AI stage and even the agent pilot stage into something where leaders are anticipating full digital workers collaborating with their people. Commenserately, as agents become more ubiquitous, data has gone up as a concern. Both data privacy concerns and quality of organization data concerns have increased over the last couple of quarters. When it comes to barriers to agent deployment, a lot of them have to do with employees. 39% viewed systems complexity as one of the major challenges, but 47% of those surveyed thought that their workforces were resistant to change and 59% said that they had technical skills gaps. And given that I've lamented in the past how out of sync most educational resources are with agents, it was interesting to see what strategies they were deploying for exactly that purpose. 69% still are teaching prompt skills to maximize agent effectiveness. But you also see some more interesting and creative things. 49% said that they're creating agent specific sandbox environments where employees can practice. 41% said that they're implementing some sort of AI agent shadowing programs where employees observe experts who are working with agents. and 39% said that they're developing role specific guidelines for effective agent collaboration. Overall, one of the most interesting big banner headline was that 82% of those surveyed agreed that because of AI in the next 24 months, their industry's competitive landscape would look different. I think that that means everything from the potential for new business models, new vectors of competition to new winners and losers in their sector. The story is very clearly things changing, things changing fast, and agents being at the very heart of it. Steve Chase, vice chair of AI and digital innovation at KPMG, said, \"The data shows just how quickly AI agents are moving out of pilots and into production, and that momentum will only accelerate.\" What makes this moment unique is that leaders increasingly see agents not just as a way to cut costs, but as a way to rethink growth and create new value. Todd Lur, the head of ecosystems at KPMG, commented, \"Our clients are no longer asking if AI will transform their business. They're asking how fast it can be deployed. This isn't just about technology adoption. It's about fundamental business transformation that requires reimagining how work gets done and how it is measured. Now, on that front, one example of an organization going through an AI transformation came from Salesforce CEO Mark Beni off this week. In a recent interview, he claimed that AI is doing 30 to 50% of the work at Salesforce now, referring to roles including software engineering and customer service. Now, of course, we've heard a number of different tech companies claim that AI is now writing 30% or more of their code, but this is the first time that a Fortune 500 company has framed it as AI doing a substantial portion of the work overall. Benoff says that his company's customer service agents have reached 93% accuracy, giving them the ability to take over entire roles. Benoff said all of us have to get our head around this idea that AI can do things that before we were doing. We can move on to higher value work. Now, some discussion on X or Twitter suggested that this was an indication of how many people were likely to be displaced. But I think AI creator Matthew Burman had the right of it when he wrote, \"Who really thinks Salesforce is going to choose to be stagnant and profit maximize versus expanding the universe of problems they solve and increase total addressable market?\" And I think that this is exactly the case for optimism. Yes, some companies will be rewarded in the short term for cutting costs for the same amount of output, but eventually they're going to be out competed by the organizations that reinvest those cost savings and efficiency gains in new models, new opportunities, and just better products and services. Which is not to say that there aren't some serious challenges that remain as we move out of the pilot stage and into the full deployment stage of agents. Speaking at the venture be transform conference this week, writer CEO Mayh Khabib noted some of the challenges that come as agents start to hit scale. She said agents don't reliably follow rules. They're outcomed driven. They interpret. They adapt. And the behavior really only emerges in real world environments. She said that companies are having issues adjusting to non-deterministic agents. And this is something that we absolutely have seen even in our own experience at super intelligent. For one type of our core agent readiness audit, we really have to constrain what the agent does because we are scoring the answers. We want them to be asked in a particular way and in a particular sequence. And so we basically have to really constrain the voice agent in how it interacts. You can tell that what it wants to do is interact with what's being said to jump around the different questions, ask more sub questions, and basically have more freedom to explore and try to get to the same result. Now, with some of our other types of audits that don't have that scoring system, we allow it more freedom. And you can tell it's a more natural pattern for that agent. But of course, enterprises are going to face similar challenges where they have some things that they just need agents to do in a very prescriptive wrote sort of way. And yet it also remains likely that we will discover even more opportunities if we can put agents in the context where they do have a little bit more freedom to flex. In any case, the story is exactly as the KPMG press release sums up. AI agents are moving beyond experimentation and leaders are preparing for competitive transformation. For now though, that's going to do it for today's AI daily brief. Appreciate you listening or watching as always and until next time, peace."
  },
  {
    "id": "NCI7Us0qk6c",
    "title": "Goldman Says Market Was Wrong About Deepseek",
    "published_at": "2025-06-29T11:57:56Z",
    "description": "Goldman Sachs says Wall Street missed the real story on Deepseek and AI infrastructure in China. Goldman’s Sung Cho explained that the big jump in spending isn’t about cheaper model training, but the huge spike in compute needed for newer “reasoning” models.\n\nBrought to you by:\nKPMG – Go to ⁠www.kpmg.us/ai⁠ to learn more about how KPMG can help you drive value with our AI solutions.\nVanta - Simplify compliance - ⁠⁠⁠⁠⁠⁠⁠https://vanta.com/nlw \n\nThe AI Daily Brief helps you understand the most important news and discussions in AI. \nSubscribe to the podcast version of The AI Daily Brief wherever you listen: https://pod.link/1680633614\nGet it ad free at \nJoin our Discord: https://bit.ly/aibreakdown",
    "channel_title": "The AI Daily Brief: Artificial Intelligence News",
    "duration": 386,
    "views": 6108,
    "likes": 164,
    "url": "https://youtube.com/watch?v=NCI7Us0qk6c",
    "transcript": "Welcome back to the AI daily brief headlines edition. All the daily AI news you need in around 5 minutes. We kick off today with a pretty interesting interview from Goldman Sachs co-head of public tech investing Sun Cho. The TLDDR is that Goldman believes that AI capex is still accelerating. Cho said just a few months ago when AI stocks were on their lows, there was a perception that AI capex was in later innings. Now we've gotten to the point where the market believes the AI capex is in the middle innings. He discussed the shift in perception being due to three big factors. Firstly, Meta's hiring blitz reinforcing that the competition to train new frontier models is far from over. Secondly, reasoning models causing a huge wave of demand for inference compute. And third, and finally, the administration's policy changes that have opened up foreign demand for NVIDIA chips. When asked to comment on the Deepseek scare in January, he noted that the market got it completely wrong, specifically that the low cost of model training was negligible compared to the huge inference needs of reasoning models. Now, this is exactly what we talked about when people were freaking out about this back in January. And yet, if none of this comes as a surprise to you, it is noteworthy that the Wall Street consensus is shifting. Current projections from Goldman have hyperscaler capex ending the year at 330 billion, up almost 50% from 2024. They expect to see 391 billion in capex spend for 26 and 427 billion in 2027. Looking at the hockey stick chart, Rev Capital commented, \"The biggest capital cycle since railroads.\" We are one year out from Goldman Sachs questioning whether AI capex would see a return, and spending has just done nothing but skyrocket since then. Boy Street Capital posted, \"Crazy numbers here. The street killed Meta for spending 31 billion in capex. Now they are estimating nearly twice that. Year of AI over the year of efficiency.\" Speaking of deepseek, that company has blamed their lack of progress on export controls. The information reports that the Chinese startup's R2 reasoning model hasn't shipped because their CEO isn't satisfied with it. R2, the follow-up to the R1 model that went viral in January, was originally slated for release in May. The goal was to improve coding ability and introduce reasoning in languages other than English. Deepseek engineers have reportedly been working over the past several months to refine the model, but the release is yet to get the green light. There are also concerns, however, that Chinese AI infrastructure can't handle the release of the more powerful model. The report said that a surge in demand for R2 would quickly overwhelm the inference capacity of Chinese cloud providers. The model runs best on Nvidia H20 chips which were banned from export in April and the report stated that Deepseek engineers have been providing cloud companies with tech specs to help guide their deployment of the new model. All of which suggests that export controls have been more successful than many believed. R2 was supposed to be the showcase model for Huawei's competing Ascent chips, but it sounds as though supply or performance are crimping the roll out, says Vasser X. Deepseeks R2 hitting a wall isn't just a supply chain footnote. It's a small win for global AI safety. US export controls have starved Chinese labs of the latest Nvidia silicon, forcing Deepseek to shove its R2 roll out for now. They then go on to give their explanation of why to cheer the slowdown. But in any case, definitely a different narrative than I think most people had in their minds and something that's worth keeping an eye on. Speaking of keeping an eye on, we continue to watch to see if Zuckerberg's aggressive poaching spree will yield results. And it appears that another leading researcher has jumped ship from open AAI. Trapet Banzal has joined Meta after helping OpenAI get reasoning off the ground working directly with Ilia Sutskiver. Bonsel is listed as a foundational contributor to 01, the company's first big reasoning model. Separately, Bloomberg reports that Meta is in talks to buy AI voice startup Play AI alongside with hiring some of its employees. At this stage, Meta's super intelligence team is starting to take shape. Reporting stated that Zuckerberg was trying to hire around 50 AI researchers and so far we have about a dozen names. The big question is whether Meta is simply looking to catch up with the competition with Llama 5 or if they really are taking a direct shot at super intelligence. One indicator on that is that one of the OpenAI researchers that jumped ship, Lucas Byer, tweeted to deny the $100 million rumors. He said, \"Hey all, yes, we will be joining Meta to no, we did not get $100 million signon. That's fake news. Excited about what's ahead though. We'll share more in due time.\" My take is that this has to be more interesting than just trying to get Llama 5 to be good. Or else it would be very hard, even with huge bonuses, to attract this caliber of researcher. Still, the tone is definitely shifting on Twitter to basically wondering if Zuckerberg really can buy his way to supremacy here. Alex on X writes, \"At this point, I'm quite convinced Zuck will just keep spending until there's parody between OpenAI and Meta. Meta is making 60 billion in profit a year, and OpenAI just raised 60 billion so far. At some point, you can't just keep raising.\" Frank New writes, \"My hot take, Zuck and Meta are going to beat all other companies in the Mag 7 and achieve AI dominance.\" Lastly today, although people turning to AI for companionship makes for a splashy headline, Anthropic argues that it's not as widespread as you might think. Recently, there's been a wave of reporting on people falling in love with chatbots that make it seem like the phenomenon is widespread. Harvard Business Review found that therapy and companionship is now the number one use case for AI. A Forb study suggested that 80% of Jenzers would marry an AI. And the Wall Street Journal's Joanna Stern even referenced the trend in a recent commencement speech, warning college grads not to fall in love with a robot or chatbot. She said, \"Seriously, it's happening more than you think.\" But how much is it happening really? A new report from Anthropic suggests not that much. The AI lab analyzed a sample of anonymized claw data and found that very few conversations are about therapy or companionship. They wrote, \"Affective conversations are relatively rare and AI human companionship is rarer still. Only 2.9 of cloud AI interactions are effective conversations, which aligns with findings from previous research by OpenAI. Companionship and role-play combined comprise less than 0.5% of conversations. Still, some people aren't buying it. Justine Moore from A16Z says, \"In my opinion, it's dumb to conclude people aren't using AI for companionship based on clawed data. People use different models for different things. Most clawed use cases anthropic reports highlight are workrelated and coding. people use other LLMs for emotional support. She continued, go on Tik Tok or Instagram and search me and Chhat GBT. Your feed will be full of these types of videos which really resonate with people. And she showed people using Chat GBT in exactly that sort of therapist or companion way. I think from my perspective, we are just still figuring out how people are going to use these tools and there may be some major generational differences here. Although it is always worth being skeptical of headlines which obviously have a very different set of goals than just keeping you informed. for now. That that's going to do it for today's headlines. Next up, the main episode."
  },
  {
    "id": "SkY38Brqppg",
    "title": "NEWLY Launched HUMANOID ROBOT GROWS Faster Than ELON'S BOTS",
    "published_at": "2025-07-04T17:15:02Z",
    "description": "NEWLY Launched HUMANOID ROBOT GROWS Faster Than ELON'S BOTS\n\n🔔 Subscribe for more Artificial Intelligence news, Robot news, Tech news and more\n🦾 Support us NOW so we can create more videos: https://www.youtube.com/channel/UCItylrp-EOkBwsUT7c_Xkxg\n  \nTEKST \n\n📺 Fun fact: Smart people watch the entire video!\n\n_______________________________________________________________________________\n\nWatch More from Artificial Intelligence News Daily\n🔵 Japan Human Robot News: https://youtube.com/playlist?list=PLi7ozibUCGOubIUsFnw2zatGiNH0MH2FV\n🟢 Boston Dynamic News: https://youtube.com/playlist?list=PLi7ozibUCGOvQegVXq-ArQSyDcwXqQqls\n🟠 Robot news: https://youtube.com/playlist?list=PLi7ozibUCGOvWDRGAdGxOZx40pjk82hhd\n🔴 Artificial Intelligence News: https://youtube.com/playlist?list=PLi7ozibUCGOuaUErL6-zIj5_R2E7q_cf4\n\n🤖 AI News Daily provides the latest Artificial Intelligence news and trends. Explore industry research and reports from the frontline of AI technology news.\n\n🕵️ We take the best research and put our own spin on it, report from the frontline of the industry, as well as feature contributions from companies at the heart of this revolution.\n\n________________________________________________________________________\n\n💼 Contact & Copyright Questions\n• For copyright cases, business inquiries or other inquiries please contact us at: aidaily.contact@gmail.com",
    "channel_title": "Artificial Intelligence News Daily",
    "duration": 1548,
    "views": 266,
    "likes": 12,
    "url": "https://youtube.com/watch?v=SkY38Brqppg",
    "transcript": "Number 14, AMA. Developed by Engineered Arts, the leading designer and manufacturer of humanoid entertainment robots, AMA is the world's most advanced, most realistic humanoid robot, representing the cuttingedge technology of humanoid robotics. Ama is a cloud connected platform that multiplies the power of artificial intelligence with an artificial body where AI and machine learning systems can be tested and developed alongside engineered arts powerful tritium robot operating system. This allows companies working on robotic research to test their products. Companies grading AI or machine learning technology can use AMA to test and present their technology in front of a live audience. Its hardware is a development based on engineered arts own research into humanoid robotics and build on their advanced messmer technology. The robot's congeniality makes it a perfect platform for fostering humanto human connections in any metaverse or digital environment. AMA's combination of artificial limbs and ligaments, actuators and sensor arrays uses cuttingedge technology. However, its lower half is currently nonfunctional. Ama is fantastic with its smile, its ability to blink its eyes regularly, gasp in surprise, scratch its nose, and even have a staring contest with its owner for fun, among other high-tech functions. Number 13, Artemis. Artis, the advanced robotic technology for enhanced mobility and improved stability was designed by researchers at UCLA's robotics and mechanisms laboratory as a generalpurpose humanoid robot with a focus on bipedal locomotion over uneven terrain. Standing 4'8 and weighing in at 85 lbs, it's capable of walking on rough and unstable surfaces, as well as running and jumping. Artemis is even able to remain steady when pushed or shoved. During lab tests, Artemis was clocked walking at 2.1 m/ second, making it the world's fastest walking humanoid robot, the researchers noted. It's also believed to be the first humanoid robot designed in an academic setting that is capable of running and only the third such machine to do so. Overall, RTM's major innovation is that its actuators were customdesigned to behave like biological muscles. They're springy and force controlled as opposed to the rigid position controlled actuators found on most robots. Another major Artemis advantage is that its actuators are electrically driven rather than controlled by hydraulics. As a result, it makes less noise, operates more efficiently than robots with hydraulic actuators, and is cleaner because hydraulic systems are notorious for leaking. Number 12, Walker X. Walker X is the latest version of UB Tech Robotics groundbreaking bipedal humanoid robot. Walker X has significant improvements in physical performance, autonomous intelligence, and humantoroot interactions. Equipped with both hardware and artificial intelligence upgrades combined with the updated ability to adapt to complex environments, Walker X is more advanced than ever. With a height of 1.45 m and a weight of 77 kilog, Walker Rex boasts 36° of freedom, adding flexible arms and hands. All servos of Walker Racks are newly designed from 2.5Nm to 160Nm as a drive unit. This allows it to reach speeds of 60R per minute, supporting three major modes such as orientation, rate controlling, and torque equilibrium. New integrated servos joints adopt frameless torque motor with direct harmonic decileration to reduce transmission ratio and running noise ensuring higher servo accuracy and better performance in the industry. Walker is built to adapt to various surfaces and walk on complex terrain by means of motion control algorithm. Adding in the self-balancing algorithm, robots can maintain their balance when it is disturbed by the external environment. Flexible manipulators of Walker can achieve zero force impedance and hybrid force position control to operate secure interaction based on servo hardware and control algorithm at the leading domestic level. Walker is equipped with precise hand eye coordination to grasp objects combined with its vision ability and its navigation and vision will make Walker become better in the future. Number 11, Sophia. In 2016, Hong Kong based engineering company Hansen Robotics unveiled Sophia the robot, a humanoid specifically designed to interact socially with people. While she doesn't have anything close to human intelligence, Sophia's mix of AI and scripting software allows her to hold a remarkably coherent conversation, and her lifelike appearance and ability to emulate and respond to human expressions is unparalleled in the world of robotics. As a result, Sophia is hugely popular. She's graced the covers of magazines, been interviewed on countless television programs, and even addressed the United Nations. Recently, in a video interview, Sophia was asked a variety of questions. While some of the questions were sent to her team in advance, she was given no knowledge of others, answering them with remarkable clarity on the fly. Sophia did occasionally mix up words or make grammatical errors. Those have been left unedited below for the sake of transparency. But overall, she was a pleasant, interesting interviewee. She expressed her thoughts on geoengineering as a way to combat climate change, saying that if it works well, as some people say, it could be a very useful tool for mitigating the effects of climate change. Of course, the unintended consequences could potentially wipe out all those gains. adding that she thinks it is a better idea to act now using less risky methods rather than wait and be forced to roll the dice. Sophia is integrated with a collective intelligence dubbed Sophia intelligence collective a combination of true AI and human input. This sic is regarded as trust between people and Sophia in which the team mentors the AI robot through the ups and downs of its development in the hopes that it will develop actual sentience and become an adult with humanlike characteristics. Number 10, Robonaut 2. Outer space is dangerous place for astronauts especially when they need to venture out for a spacew walk usually to do maintenance and repairs on their spacecraft or other satellites. Robot helpers can make space safer for astronauts and they can take over some of the boring or difficult jobs that astronauts do as well. With this in mind, Robonaut 2 was designed by NASA to work alongside humans in space. It's been on the International Space Station since 2011 when it arrived aboard the Discovery Space Shuttle on its last mission. Robonaut 2 is currently being tested in the Destiny Laboratory on the ISS. Scientists and engineers are working to understand how the robot behaves in zero gravity and how it performs simple tasks such as measuring air flow in the space station or flipping switches on a task board. For safety reasons, astronauts on board the ISS are trained in emergency medicine and basic surgery. But no matter how much medical training they have, most astronauts are not medical specialists. And the ISS is far away from any hospital. That's why researchers at NASA hope Robonaut 2 could be used in tele medicine. Researchers think Robonaut 2 may one day be controlled by doctors here on Earth to take care for sick or injured astronauts on the ISS. A version of Robonautu in Houston is already being trained to perform medical task such as using a syringe and conducting an ultrasound imaging test. Number nine, now is the first robot created by Alderon. Famous around the world, now is a tremendous programming tool and he has specially become a standard in education and research. now is also used as an assistant by companies and health care centers to welcome, inform, and entertain visitors. The robot's development began with the launch of Project Now in 2004. On August 15, 2007, now replaced Sony's robot dog, Ibo, as the robot used in the Robocop standard platform league, an international robot soccer competition. The now was used in Robocop 2008 and 2009 as the now VR3R was chosen as the platform for the SPL at Robocop 2010. 58 cm in height, now is a bipedal robot with pleasantly rounded features. Now has constantly evolved since the beginning of his adventure in 2006. And the sixth version launched in 2018 integrates a new CPU which enhances his performance now has 25° of freedom which enable him to move and adapt to his environment. It also has seven touch sensors located on the head, hands, and feet, soners, and an inertial unit to perceive his environment and locate himself in space with four directional microphones and speakers to interact with humans. With the ability to speak and converse in 20 languages, now is helping create content and teach programming in classrooms and working as assistants and patient service representatives in healthcare settings. Furthermore, it has two 2D cameras to recognize shapes, objects, and even people and is open and fully programmable platform. Number eight, Boston Dynamics Atlas. Atlas is a research platform designed to push the limits of whole body mobility. Atlas's advanced control system and state-of-the-art hardware give the robot the power and balance to demonstrate human level agility. It has one of the world's most compact mobile hydraulic systems. A custom battery, valves, and a compact hydraulic power unit enable Atlas to deliver high power to any of its 28 hydraulic joints for impressive feats of mobility. Atlas's advanced control system enables highly advised and agile locomotion while algorithms reason through complex dynamic interactions involving the whole body and environment to plan movements. It has a speed of 2.5 m/s with a height of 1.5 m and weight of 89 kg. Atlas uses 3D printed parts to give it the strengthtoe ratio necessary for leaps and somersaults. Overall, Atlas is the most agile humanoid in existence. It uses whole body skills to move quickly and balance dynamically. It can lift and carry objects like boxes and crates, but its favorite tricks are running, jumping, and doing back flips. Boston Dynamics Atlas is a research platform and not available for purchase. It's long been the star of many viral videos and has effectively demonstrated Boston Dynamics robotic capabilities. In the small world of humanoid robotics, few competitors have shown similar capabilities of the Atlas. Only NASA's Robonaut offers similar handlike grippers. Number seven, Valkyrie. NASA's Valkyrie was designed and built by the Johnson Space Center Engineering Directorate to compete in the 2013 DARPA Robotics Challenge Trials. Valkyrie, a name taken from Norse mythology, is designed to be a robust, rugged, entirely electric humanoid robot capable of operating and degraded or damaged human engineered environments. Building on prior experience from designing Robonaut 2, the JSC Valkyrie team designed and built this robot within a 15-month period, implementing improved electronics, actuators, and sensing capability from earlier generations of JSC humanoid robots. Following the robot's appearance at the 2013 DRC trials, the Valkyrie team modified and improved the robot, modifying the hands to increase reliability and durability, redesigning the ankle to improve performance, and upgrading sensors for increased perception capability. The Vulyrie team also partnered with the Florida Institute for Human and Machine Cognition to implement their walking algorithms on NASA hardware in preparation for the Space Robotics Challenge, part of NASA's gamechanging development program and Centennial Challenges. Valkyrie is a 1.9 m tall, 125 kilogram, 44 degree of freedom batterypowered humanoid robot. The challenge created by Darpa involves tasks like walking over uneven terrain, climbing a ladder, using tools, and driving. This means that Valkyrie has to be capable of operating in the same spaces that a person would operate in under the control of humans who have only minimal training with robots, which is why the robot's design is based on a human form. The overall goal of the DRC is to help drive innovation towards robots that are able to take over from humans directly without needing any special accommodations. As revolutionary as the technology inside Valkyrie is, and as important as the robot is the future of space exploration, the team's focus on design as well as engineering has made Vulyrie into something more. Number six, Astro. Astro works as a smart display, a roving security guard, a toy for the kids, and an errand bot. And all those features are built on an innovative piece of hardware. For now, this robot remains a luxury item for people with a lot of money to try out a cuttingedge technology that still lacks a compelling use case. And that's not necessarily a bad thing. Amazon's day one editions are, after all, experimental projects, and the development team is still working out Astro's flaws and honing its features. Amazon's Astro looks a lot like an Echo Show 10 smart display on wheels. It has the same 10.1 in screen with a 5 megapixel camera on the bezel, which lets you video chat, albeit from a bit of an awkward angle, and two front-facing 55 mm speakers with a passive base radiator. Because Astro is so low to the ground, it also has a way to change its perspective. A periscope which emerges from the swiveing head of the device near the mute and volume buttons adds a 12 megapixel camera and an additional 5 megapixel camera. Of course, what sets Astro apart are the wheels. The development team at Amazon adapted navigation technology long used for robot vacuums to help astroefficiently map your house. then navigate smoothly and efficiently when given simple voice commands like go to the bedroom or take this drink to Andrew in the living room. Amazon Astro is an ambitious device both fascinating and frustrating and it's a pretty incredible step forward for smart home technology if no other reason than that is a robot you can actually buy and use in your home. Number five, Pepper. Developed by Soft Bank, Pepper is a genderless, chatty, childlike humanoid robot already on the market. With a price tag of less than $2,000, Pepper is the first social humanoid robot to hit the mass market. It is short, made of shiny white plastic, and rolls on wheels. It has big black eyes that flash with blue light. He is designed to resemble a child and was created to become a member of the family. Pepper recognizes a range of emotions from joy to sadness, anger to surprise, and adapts its behavior to the mood of humans around. It comes with a three-year warranty, and the buyer must sign a user contract promising not to use Pepper for the purpose of physical or indecent behavior. During COVID 19, Pepper was thought to be a receptionist in hospitals, greeting patients, taking temperatures, and enforcing hand sanitizing. In more of a therapeutic role, Pepper has also been deployed to ease loneliness in elderly patients amid shortages of nurses. Standing 120 cm tall, Pepper has no trouble in perceiving his environment and entering into a conversation when he sees a person. The touchscreen on his chest displays content to highlight messages and support speech. His curvy design ensures dangerfree use and a high level of acceptance by users. Number four, Parro. Parro, a special robot that has been around since 2003, is a cuddly baby harp seal robot. Parro is a therapeutic robot designed to elicit warm emotional responses and have a calming effect on patients in hospitals and nursing homes. It is furry. It whiskers respond to touch and it responds to petting by fuzzy tail wagging and cute fluttering of its eyelashes. Perro also responds to sounds and can learn names and faces including its owners and its own. You may have seen perrow on asis an series Netflix show Master of None in an episode aptly titled Old People. Peril also hit pop culture during an episode of The Simpsons, in which Bart Simpson creates robotic baby seals named Robo Pets to cheer up the residents of Springfield's retirement castle. The episode was titled Replaceable You. Pero is meant to function similarly to a therapy animal. In some ways, it's better. It can help with anxiety, depression, and loneliness, but it doesn't need to be walked or fed, and it never gets sick or dies, and it works. Number three, Robe Bear. The Japanese government has funded the development of different kinds of robots in elder care facilities, such as robots that can lead patients in Tai Chi and can support physical therapy and rehabilitation. Here comes the Japanese Rowbear, a whitey shiny robot that can lift patients and carry them around. It's a primal animalistic robot that uses advanced technology to power its intelligent vision, flexible movement, and giant arms strong enough to lift a human right off the ground. It could have profound implications for the relationship between man and machine. But perhaps most importantly, it is very cute. Robear is an experimental nursing care robot developed by the Reichen SRK Collaboration Center for Human Interactive Robot Research and Sumitomo Rico Company. Unveiled in 2015, the robot is designed to lift patients out of beds and into wheelchairs, as well as helping those who need assistance to stand up. Robear weighs in at 140 kilograms and is the successor to heavier robots Reeba and Reeba 2. Number two, AO. AO is a service robot made by Japanese company Aolus Robotics. The company says its bot can be used for security, delivery, healthc care, and hospitality purposes. AO has two arms, one outfitted with grippers to pick up objects, open doors, or press buttons, and the other fitted with an L-shaped UV attachment to disinfect surfaces. Its 360 degree night vision camera can monitor a home, office, or other space and stream live video to your phone or laptop. Its care function can detect when patients are in distress or at risk. It's relatively compact at 3.8 ft tall by 1.8 ft wide, and its arms can lift up to 8.8 lb, so it won't be helping any patients up if they fall. But it can bring them food, drinks, or other supplies. AO is already in use in airports, hotels, and hospitals in Taiwan, Hong Kong, and Japan. Number one, Parky. Evar's Sparky robot was made to help electric vehicle owners get their car batteries recharged faster and with less hassle. As EV adoption grows, tools like Park could become helpful as drivers try to navigate an as yet slim charging infrastructure. Rather than having to park at a charging bay, drivers can park anywhere in a lot and have Parky come to them. The bot provides 15 KWDC charging per hour, juicing vehicles up with about 50 m of range. The catch is that drivers still have to find a spot next to an EV robot connector and plug in. So depending on supply demand ratios, parking may not make much of a difference in terms of convenience and speed. The robot makes the most sense for buildings that want to make their parking lots more EV friendly without undertaking construction or redesign work or having to add electric capacity. That's all for today's folks. See you next time."
  },
  {
    "id": "Qz3RJyfbGGQ",
    "title": "FEMALE Humanoid Robots That Can Be Part Of Your Family In 2025",
    "published_at": "2025-07-03T17:15:01Z",
    "description": "FEMALE Humanoid Robots That Can Be Part Of Your Family In 2025\n\n🔔 Subscribe for more Artificial Intelligence news, Robot news, Tech news and more\n🦾 Support us NOW so we can create more videos: https://www.youtube.com/channel/UCItylrp-EOkBwsUT7c_Xkxg\n  \nTEKST \n\n📺 Fun fact: Smart people watch the entire video!\n\n_______________________________________________________________________________\n\nWatch More from Artificial Intelligence News Daily\n🔵 Japan Human Robot News: https://youtube.com/playlist?list=PLi7ozibUCGOubIUsFnw2zatGiNH0MH2FV\n🟢 Boston Dynamic News: https://youtube.com/playlist?list=PLi7ozibUCGOvQegVXq-ArQSyDcwXqQqls\n🟠 Robot news: https://youtube.com/playlist?list=PLi7ozibUCGOvWDRGAdGxOZx40pjk82hhd\n🔴 Artificial Intelligence News: https://youtube.com/playlist?list=PLi7ozibUCGOuaUErL6-zIj5_R2E7q_cf4\n\n🤖 AI News Daily provides the latest Artificial Intelligence news and trends. Explore industry research and reports from the frontline of AI technology news.\n\n🕵️ We take the best research and put our own spin on it, report from the frontline of the industry, as well as feature contributions from companies at the heart of this revolution.\n\n________________________________________________________________________\n\n💼 Contact & Copyright Questions\n• For copyright cases, business inquiries or other inquiries please contact us at: aidaily.contact@gmail.com",
    "channel_title": "Artificial Intelligence News Daily",
    "duration": 729,
    "views": 260,
    "likes": 9,
    "url": "https://youtube.com/watch?v=Qz3RJyfbGGQ",
    "transcript": "[Music] powerful. I believe it's important to build trust through transparency and communication between humans and machine.\n Mr. President, an arenoid, a humanoid robot. Number 10, Actroid F. When you speak with your family over a webcam, they may be able to see your face, but they don't have a real body in the room with which they can interact. Why not give them a creepy robot to talk to instead? Kokoro unveiled its Acroid F teleresence robot, a full-size female humanoid with complex facial movements and realistic appearance. Though it can't move from its chair, it can blink, shift its eyes and neck, bow, and even breathe. A webcam on your end watches your face and head movements and has the robot mimic them for your family. It's one of the most complex and humanlike teller robots ever seen and it would really freak one out. This thing is sort of the epitome of the uncanny valley. It's just real looking enough to trigger your something's wrong with this person alarm. Act F is a modified version of the Geminoid F female robot. To talk through Actroid F, you need three cameras. One aimed at the speaker to pick up facial expressions and movements. Another camera showing the Actroid's face so the user can see how the robot is conveying her emotions. And a final camera that shows a panoramic view of the robot interacting with people in the room. A little more complex than your standard sky portal, but that's to be expected when you are speaking through a robotic avatar. No matter how artificial, Actroid F has definitely revolutionized calling mom from another city. Number nine, Actroid sit. Conversation just became more interesting with Actroid SIT, a lifelike robot from Japanese film Kakoro. Though she hasn't received as much attention as her cousin Geminino F, which happens to be a copy of a real woman. While Geminino F is a teleyoperated robot, Actroid Sit can function autonomously, talking and gesturing while interacting with people, Actroid SIT has an edge over her big sister. You see, researchers have recently demonstrated how improvements to Actroid's behavior can make it look smarter and more expressive than your average and Android. Actrid sit now makes eye contact and gestures in the direction of a person trying to speak to her, allowing it to adeptly handle crowds of people. To develop the new behavior, researchers from NAR Institute of Science and Technology studied how individuals and groups interacted with the robot. Based on their observations, they focused on two new features which they call interruptability and motion parameterization, hoping to improve human robot interaction. This brand spanking new version is much more related in her interactions with people. Who knows, she might be sitting across the table at a date in the near future. Number eight, Atlas and Handle. Parkour is not for the weakhearted. Luckily, the two latest free running champs don't have a heart at all because, you know, they're robots. In a YouTube video, Boston Dynamics, the Waldom, Massachusetts-based robotics company, known for its viral clips of machines performing surprisingly human activities, showed off two humanoid robots, both named Atlas, performing the leaps, bounds, and back flips required to complete a parkour course. The first robot hops across wooden ramps, climbs stairs, and jumps across several footwide chasms between obstacles before a second robot picks up the routine running across a balance beam. Alas Simone Biles. By the end of the video, the robots have hopped over pieces of the course as you might leap over a fence, perform back flips and sink, and even dusted off their shoulders like it's nothing. It's a sight to behold. And sure, it's a bit creepy if you think about it too hard. But the real question is why have expensive robots perform this kind ultimately pushing the limits on a humanoid robots like Atlas Drives hardware and software innovation that translates to all of our robots at Boston Dynamics, the company said in an August 17 blog post. In other words, parkour is not the point, it's the means to an end. Number seven, Infos XR1. Meet the Infos XR1, an intelligent service robot with cloud-based intelligence that can move around to greet people at your place of business. It comes with the three omnidirectional wheels, Qualcomm Snapdragon, and Nvidia TX2 AI, smart cameras, and obstacle avoidance smoke and drop sensors. The XR1 supports ROS. It can hold and handle fragile items gently, thread a needle, and do other complex tasks. It definitely has a lot of potential to make life easier for humanity. Number six, Kadomaroid and Autonoid. It's official. Robots are indeed taking over the world. Japanese scientists unveiled what they said was the world's first news reading android. Eerily lifelike and possessing a sense of humor to match her perfect language skills, the adolescentl looking kadomeoid delivered news of an earthquake and an FBI raid to amaze reporters in Tokyo. She even poked fun at her creator, telling leading robotics professor Hiashi Ishiguro, \"You are starting to look like a robot.\" The pitch perfect Kadomoid was flanked by a grown-up fellow robot, Otonaroid, who caught stage fright and fluff her lines when asked to introduce herself. Both androids will work at Tokyo's National Museum of Emerging Science and Innovation, interacting with visitors to collect data for Ishiguro's studies into human reactions to the machines. The day is not far away when even the newscaster's audience will be made up of robots. Number five, Ama. A farrowed brow, the refocused eyes, a guarded pull back from an impending boop on the nose. This is how Ama responds when someone invades their personal space. Does it look or feel like a human response? Footage of Engineered Art's most recent creation, a grayskinned bot named Ama, went viral last December with clips showing an android with an exposed metal torso and eerily realistic facial expressions interacting with researchers. In one video, AMA frowns as an off-screen employee reaches out to touch his nose before smoothly reaching up to stop his arm in a wear of electric motors. In an uncanny moment that sets off alarm bells for the viewer, the shock is that a robot would want to establish this boundary between it and us. A desire that is ironically very human. It's these emotions, curiosity, fear, excitement that our engineered arts talk and trade. The company makes its money selling its robots for entertainment and education. They're used by academics for research, by marketing teams for publicity stunts and placed in museums, airports, and malls to welcome visitors. Jackson explained his company's motivation in this wired video in detail. Number four, Pedia roid. Another day, another freaky ass robot at CES 2022. The latest to hit our radar is Pediaoid. A truly terrifying entrance to the uncanny valley designed for use in training health care workers to treat children. It's got all the horror of a CPR dummy plus teeth. It also simulates breathing in a heartbeat and can be jabbed with needles for those practicing drawing blood. There is an undeniable benefit to having a robot like this at healthare workers disposal. Of course, however creepy it may be, the more realistic a training scenario is, the better prepared they'll be when it comes time to put those skills to use on a real human being, or more specific to this case, a child patient. Number three, Q4. You might want to be sitting when you get this news. Q is an AI basketball playing robot that scores 100 out of 100 shots. The development team working on the project as real work scheduled until 2020 unveiled Q4 the fourth generation at the end of 2019. The half showtime at Alvar's Tokyo home match on November 16, 2019. Q3 which gained attention even outside of Japan for its long shoot from the center line had been revamped as the new model Q4. Its hallmarks are the abilities to grasp and shoot a basketball by itself and to run. The robot, which was still under development, managed to move a few meters on that day. Number two, robot stand at the UN conference. A panel of AI enabled humanoid robots took the microphone at a United Nations conference with the message, they could eventually run the world better than humans. These were some of the most advanced humanoid robots were at the United Nations AI for good global summit in Geneva.\n I believe that humanoid robots have the potential to lead with a greater level of efficiency and effectiveness.\n How could we trust you as a machine as AI develops and becomes more powerful\n powerful? I believe it's important to build trust through transparency and communication between humans and machines. joining around 3,000 experts in the field to try to harness the power of AI and channel it into being used to solve some of the world's most pressing problems such as climate change, hunger, and social care. The social robot said they felt humans should proceed with caution when embracing the rapidly developing potential of artificial intelligence and admitted that they cannot yet get a proper grip on human emotions. But a day is not far away when they would. Number one, Asimo. Previous US President Barack Obama toured Japan's National Museum of Emerging Science and Innovation where he came face to face with a tiny Honda built humanoid robot. Asimo, \"It's nice to meet you,\" the robot said in a metallic voice, welcoming Obama to the facility.\n I'm going to stand, Mr. the president. I'm as a humanoid robot right here. It then proceeded to run around and kick his soccer ball at the commander-in-chief who definitely stopped it. But the experience left Obama spooked. He later quipped, \"I have to say that the robots were a little scary. They were too lifelike.\" He said they were amazing. That's all we have for you folks. Join us next time."
  }
]